[{"id":"c0a885913ce34c6575f9b0ea8cad6584","title":"数据仓库Hive入门","content":"\nHive是建立在Hadoop上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载，可以简称为ETL。\n\n什么是Hive\nHive 定义了简单的类SQL查询语言，称为HQL，它允许熟悉SQL的用户直接查询Hadoop中的数据，同时，这个语言也允许熟悉MapReduce的开发者开发自定义的mapreduce任务来处理内建的SQL函数无法完成的复杂的分析任务\nHive中包含的有SQL解析引擎，它会将SQL语句转译成M/R Job,然后在Hadoop中执行。\n通过这里的分析我们可以了解到Hive可以通过sql查询Hadoop中的数据，并且sql底层也会转化成mapreduce任务，所以hive是基于hadoop的。\n\n\n\n\n\n\n\n\n\n\n简单来说Hive，是MR的客户端，也就是说不必要每台机器都安装部署Hive\nHive的数据存储\nHive的数据存储基于Hadoop的 HDFS\nHive没有专门的数据存储格式\nHive默认可以直接加载文本文件（TextFile），还支持SequenceFile、RCFile等文件格式\n针对普通文本数据，我们在创建表时，只需要指定数据的列分隔符与行分隔符，Hive即可解析里面的数据\n\nHive的系统架构\n\n\n\n\n\n\n\n\n\n\n用户接口，包括 CLI、JDBC/ODBC、WebGUI、CLI，即Shell命令行，表示我们可以通过shell命令行操作Hive JDBC/ODBC 是 Hive 的Java操作方式，与使用传统数据库JDBC的方式类似\n元数据存储(Metastore)，注意：这里的存储是名词，Metastore表示是一个存储系统 Hive中的元数据包括表的相关信息，Hive会将这些元数据存储在Metastore中，目前Metastore只支持 mysql、derby。\nDriver：包含：编译器、优化器、执行器、编译器、优化器、执行器可以完成 Hive的 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划最终存储在 HDFS 中，并在随后由 MapReduce 调用执行\nHadoop：Hive会使用 HDFS 进行存储，利用 MapReduce 进行计算Hive 的数据存储在 HDFS 中，大部分的查询由 MapReduce 完成（特例 select * from table 不会生成 MapRedcue 任务，如果在SQL语句后面再增加where过滤条件就会生成MapReduce任务）\n\n在这有一点需要注意的，就是从Hive2开始，其实官方就不建议默认使用MapReduce引擎了，而是建议使用Tez引擎或者是Spark引擎，不过目前一直到最新的3.x版本中mapreduce还是默认的执行引擎\n其实大数据计算引擎是有几个发展阶段的\n大数据计算引擎1、MapReduce首先是第一代大数据计算引擎：MapReduce\n2、Tez接着是第二代大数据计算引擎：TezTez的存在感比较低，它是源于MapReduce，主要和Hive结合在一起使用，它的核心思想是将Map和Reduce两个操作进一步拆分，这些分解后的元操作可以灵活组合，产生新的操作，这些操作经过一些控制程序组装后，可以形成一个大的作业，这样可以提高计算效率，我们在实际工作中Hive使用的就是 Tez引擎，替换Hive的执行引擎也很简单，只需要把Tez安装好（Tez也是支持在YARN上执行的），然后到Hive中配置一下就可以了，不管使用什么引擎，不会对我们使用hive造成什么影响，也就说对上层的使用没有影响\n3、Spark接着是第三代大数据计算引擎：SparkSpark在当时属于一个划时代的产品，改变了之前基于磁盘的计算思路，而是采用内存计算，就是说Spark把数据读取过来以后，中间的计算结果是不会进磁盘的，一直到出来最终结果，才会写磁盘，这样就大大提高了计算效率，而MapReduce的中间结果是会写磁盘的，所以效率没有Spark高。Spark的执行效率号称比MapReduce 快100倍，当然这需要在一定数据规模下才会差这么多，如果我们就计算几十兆或者几百兆的文件，你去对比发现其实也不会差多少，后面我们也会学到Spark这个基于内存的大数据计算引擎注意：spark也是支持在YARN上执行的\n4、Flink还有第四代大数据计算引擎：FlinkFlink是一个可以支持纯实时数据计算的计算引擎，在实时计算领域要优于Saprk，Flink和Spark其实是有很多相似之处，在某些方面他们两个属于互相参考，互相借鉴，互相成长，Flink后面我们也会学到，等后面我们讲到这个计算引擎的时候再详细分析。注意：Flink也是支持在YARN上执行的。\n\n\n\n\n\n\n\n\n\n所以发现没有，MapReduce、Tez、Spark、Flink这些计算引擎都是支持在yarn上执行的，所以说 Hdoop2中对架构的拆分是非常明智的。\n解释完这些名词之后其实我们就对这个架构有了一个基本理解， 再看来这个图 用户通过接口传递Hive SQL，然后经过Driver对SQL进行分析、编译，生成查询计划，查询计划会存储在 HDFS中，然后再通过MapReduce进行计算出结果，这就是整个大的流程。 其实在这里我们可以发现，Hive这个哥们是既不存储数据，也不计算数据，这些活都给了Hadoop来干， Hive底层最核心的东西其实就是Driver这一块，将SQL语句解析为最终的查询计划。\nMetastore接着来看一下Hive中的元数据存储，Metastore Metastore是Hive元数据的集中存放地。 Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在 的hdfs目录等 Metastore默认使用内嵌的derby数据库 Derby数据库的缺点：在同一个目录下一次只能打开一个会话 使用derby 存储方式时， Hive 会在当前目录生成一个derby.log 文件和一个metastore_db 目录， metastore_db里面会存储具体的元数据信息 没有办法使用之前的元数据信息了。 推荐使用MySQL作为外置存储引擎，可以支持多用户同时访问以及元数据共享。\n数据仓库和数据库的区别Hive VS Mysql为了加深对Hive的理解，下面我们拿Hive和我们经常使用的Mysql做一个对比\n\n\n\n\nHive\nMysql\n\n\n\n数据存储位置\nHDFS\n本地磁盘\n\n\n数据格式\n用户定义\n系统决定\n\n\n数据更新\n不支持（不支持修改和删除）\n支持（增删改查）\n\n\n索引\n有，但较弱，一般很少用\n有，经常使用\n\n\n执行\nMapReduce\nExecutor\n\n\n执行延迟\n高\n低\n\n\n可扩展性\n高\n低\n\n\n数据规模\n大\n小\n\n\n数据仓库 VS 数据库前面我们说了Hive是一个数据仓库，咱们平时经常使用的mysql属于数据库，那数据库和数据仓库到底有什么区别呢？下面我们来分析一下\n\n数据库：传统的关系型数据库主要应用在基本的事务处理，例如银行交易之类的场景数据库支持增删改查这些常见的操作。（mysql、oracle、sqlserver、DB2、sqlite、MDB）\n数据仓库：主要做一些复杂的分析操作，侧重决策支持，相对数据库而言，数据仓库分析的数据规模要大得多。但是数据仓库只支持查询操作，不支持修改和删除。（Hive，相当于MR的客户端）\n\n\n\n\n\n\n\n\n\n\n其实数据库与数据仓库的本质区别就是 OLTP与OLAP 的区别\nOLTP VS OLAP那这里的OLTO和OLAP又是什么意思呢？ **OLTP(On-Line Transaction Processing)**：操作型处理，称为联机事务处理，也可以称为面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性等问题**OLAP(On-Line Analytical Processing)**：分析型处理，称为联机分析处理，一般针对某些主题历史数据进行分析，支持管理决策。\n\n\n\n\n\n\n\n\n\n其实从字面上来对比，OLTP 和 OLAP 只有一个单词不一样OLTP侧重于事务，OLAP侧重于分析所以数据库和数据仓库的特性是不一样的，不过我们平时在使用的时候，可以把Hive作为一个数据库来操作，但是你要知道他们两个是不一样的。数据仓库的概念是比数据库要大的\nHive的安装和部署1、下载Hive安装包首先要下载Hive的安装包，进入Hive的官网，找到download下载链接。\n\n发现目前hive主要有三大版本，Hive1.x、Hive2.x、Hive3.xHive1.x已经2年没有更新了，所以这个版本后续基本不会再维护了，不过这个版本已经迭代了很多年了，也是比较稳定的Hive2.x最近一直在更新Hive3.x上次是19年8月份更新的，也算是一直在维护\n那我们到底选择哪个版本呢？注意了，在选择Hive版本的时候我们需要注意已有的Hadoop集群的版本。因为Hive会依赖于Hadoop，所以版本需要兼容才可以。\n具体Hive和Hadoop的版本对应关系可以在download页面下的news列表里面看到。\nhttps://hive.apache.org/downloads.html\n\n按照这里面说的hive2.x的需要在hadoop2.x版本中运行，hive3.x的需要在hadoop3.x版本中运行。所以在这里我们最好是使用Hive3.x的版本\n那我们就下载hive-3.1.2这个版本，如果想要下载其它历史版本的话这里面还找不到，不过可以使用apache的一个通用archive地址https://archive.apache.org/dist/hive/\n在这里面就可以找到hive的所有历史版本了\n2、克隆bd04安装hive并配置为hadoop集群客户端bd04 192.168.126.204\n\n\n\n\n\n\n\n\n\n\n编写xsyncforhost脚本，作用向指定的host机器同步指定的文件或者文件夹\n#!&#x2F;bin&#x2F;bash\n# $#：表示传递给脚本或函数的参数个数。\n#1 获取输入参数个数，如果没有参数，直接退出\npcount&#x3D;$#\nif((pcount&#x3D;&#x3D;0)); then\necho no args;\nexit;\nfi\n\n#2 获取文件名称\np1&#x3D;$1\nfname&#x3D;&#96;basename $p1&#96;\necho fname&#x3D;$fname\n\n#3 获取上级目录到绝对路径\npdir&#x3D;&#96;cd -P $(dirname $p1); pwd&#96;\necho pdir&#x3D;$pdir\n\n#4 获取当前用户名称\nuser&#x3D;&#96;whoami&#96;\n\n#5 循环\n       echo --------------- $2 ----------------\n       rsync -rvl $pdir&#x2F;$fname $user@$2:$pdir\n\n同步bd01hadoop到bd04\n[root@bd01 moudle]# xsyncforhost hadoop-3.2.0&#x2F; bd04\n3、将Hive上传到bd04虚拟机，并解压[root@bd04 software]# tar -zxvf apache-hive-3.1.2-bin.tar.gz -C &#x2F;opt&#x2F;moudle&#x2F;\n\n4、拷贝并重命名配置文件[root@bd04 conf]# cp hive-default.xml.template hive-site.xml\n[root@bd04 conf]# cp hive-env.sh.template hive-env.sh\n[root@bd04 conf]# ll\n总用量 632\n-rw-r--r--. 1 root root   1596 8月  23 2019 beeline-log4j2.properties.template\n-rw-r--r--. 1 root root 300482 8月  23 2019 hive-default.xml.template\n-rw-r--r--. 1 root root   2365 6月   2 14:38 hive-env.sh\n-rw-r--r--. 1 root root   2365 8月  23 2019 hive-env.sh.template\n-rw-r--r--. 1 root root   2274 8月  23 2019 hive-exec-log4j2.properties.template\n-rw-r--r--. 1 root root   3086 8月  23 2019 hive-log4j2.properties.template\n-rw-r--r--. 1 root root 300482 6月   2 14:38 hive-site.xml\n-rw-r--r--. 1 root root   2060 8月  23 2019 ivysettings.xml\n-rw-r--r--. 1 root root   3558 8月  23 2019 llap-cli-log4j2.properties.template\n-rw-r--r--. 1 root root   7163 8月  23 2019 llap-daemon-log4j2.properties.template\n-rw-r--r--. 1 root root   2662 8月  23 2019 parquet-logging.properties\n\n5、Centos安装MySQL8.0.16\n下载MySQL所需安装包\n从 MySQL官网 下载，上传至 CentOS 系统 /usr/local/MySQL 目录下，当然你也可以使用 wget 命令直接下载至 CentOS，此处使用的 8.0.16 版本。\n# 你想要的版本\nProduct Version: 8.0.16\n# CentOS选择Red Hat Enterprise Linux &#x2F; Oracle Linux\nOperating System:OS Version: Red Hat Enterprise Linux &#x2F; Oracle Linux\n# CentOS7 64位选择\nOS Version: Red Hat Enterprise Linux 7 &#x2F; Oracle Linux 7 (x86, 64-bit)\n检查是否存在自带mariadb\nCentOS7 开始不自带 MySQL，替换成了 mariadb，但是我们安装 MySQL 的时候会冲突，所以需要先卸载 mariadb。\n# 查找是否存在自带mariadb\nrpm -qa | grep mariadb\n\n# 如果存在则卸载, 比如我查找出来的名称为mariadb-libs-5.5.68-1.el7.x86_64\nrpm -e mariadb-libs-5.5.68-1.el7.x86_64 --nodeps\n检查是否安装过MySQL\n[root@bd04 conf]# rpm -qa | grep mysql\n# 如果存在则卸载, 比如名称为mysql-libs-5.1.52.x86_64\nrpm -e mysql-libs-5.1.52.x86_64 --nodeps\n 检查mysql组及用户是否存在，不存在则创建\n\n\n  检查\n[root@bd04 conf]# cat &#x2F;etc&#x2F;group | grep mysql\n[root@bd04 conf]# cat &#x2F;etc&#x2F;passwd | grep mysql\n# 创建\ngroupadd mysql\nuseradd -r -g mysql mysql\n\n\n安装及配置MySQL\n\n解压\n[root@bd04 software]# tar -xvf mysql-8.0.16-2.el7.x86_64.rpm-bundle.tar -C &#x2F;opt&#x2F;moudle&#x2F;mysql&#x2F;\n通过rpm命令安装common\n[root@bd04 mysql]# rpm -ivh mysql-community-common-8.0.16-2.el7.x86_64.rpm \n警告：mysql-community-common-8.0.16-2.el7.x86_64.rpm: 头V3 DSA&#x2F;SHA1 Signature, 密钥 ID 5072e1f5: NOKEY\n准备中...                          ################################# [100%]\n正在升级&#x2F;安装...\n   1:mysql-community-common-8.0.16-2.e################################# [100%]\n通过rpm命令安装libs\n[root@bd04 mysql]# rpm -ivh mysql-community-libs-8.0.16-2.el7.x86_64.rpm \n警告：mysql-community-libs-8.0.16-2.el7.x86_64.rpm: 头V3 DSA&#x2F;SHA1 Signature, 密钥 ID 5072e1f5: NOKEY\n准备中...                          ################################# [100%]\n正在升级&#x2F;安装...\n   1:mysql-community-libs-8.0.16-2.el7################################# [100%]\n通过rpm命令安装client\n[root@bd04 mysql]# rpm -ivh mysql-community-client-8.0.16-2.el7.x86_64.rpm \n警告：mysql-community-client-8.0.16-2.el7.x86_64.rpm: 头V3 DSA&#x2F;SHA1 Signature, 密钥 ID 5072e1f5: NOKEY\n准备中...                          ################################# [100%]\n正在升级&#x2F;安装...\n   1:mysql-community-client-8.0.16-2.e################################# [100%]\n通过rpm命令安装server\n[root@bd04 mysql]# rpm -ivh mysql-community-server-8.0.16-2.el7.x86_64.rpm \n警告：mysql-community-server-8.0.16-2.el7.x86_64.rpm: 头V3 DSA&#x2F;SHA1 Signature, 密钥 ID 5072e1f5: NOKEY\n准备中...                          ################################# [100%]\n正在升级&#x2F;安装...\n   1:mysql-community-server-8.0.16-2.e################################# [100%]\n查看MySQL安装包\n[root@bd04 mysql]# rpm -qa | grep mysql\nmysql-community-server-8.0.16-2.el7.x86_64\nmysql-community-common-8.0.16-2.el7.x86_64\nmysql-community-client-8.0.16-2.el7.x86_64\nmysql-community-libs-8.0.16-2.el7.x86_64\n初始化MySQL数据库\n该命令会在 /var/log/mysqld.log 生成随机密码。\n[root@bd04 mysql]# mysqld --initialize\n配置用户组\n配置MySQL数据库目录所属的用户和组，默认MySQL的配置文件路径为： /etc/my.cnf，如果有需要可以修改配置文件。\nchown mysql:mysql &#x2F;var&#x2F;lib&#x2F;mysql -R\n启动MySQL数据库\n# 启动mysqld.service\nsystemctl start mysqld\n\n# 查看状态, 显示有 running 代表启动成功\nsystemctl status mysqld\n修改数据库密码\n# 查看数据库密码\ncat &#x2F;var&#x2F;log&#x2F;mysqld.log | grep password\n\n# 打印内容, 其中w:rwf8Xvf%kw就是数据库密码\n2022-06-02T07:21:55.946368Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: w:rwf8Xvf%kw\n\n# 使用查询到的密码登录MySQL\nmysql -u root -p&#39;w:rwf8Xvf%kw&#39;\n\n# 登录到MySQL之后修改密码为自定义密码(我设置为123456), 这个设置还和5.7版本不同呢\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED WITH mysql_native_password BY &#39;admin&#39;;\n\n# 使用&#96;exit;&#96;退出MySQL后使用自定义密码重新登录\n创建用户并授权远程登录\n此处不能使用 5.7 版本的方式，不然会报错。\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;SunnyBear&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;;\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;IDENTIFIED BY &#39;123456&#39;&#39; at line 1\n复制代码\n\n8.0版本需要使用如下方式，和 Oralce 的创建授权类似，先创建用户再赋予权限。\n因为正常开发一般 root 用户不允许远程登录，所以我们创建一个 SunnyBear 用户，赋予使用 sunny 数据库(已经使用命令创建好)的权限。\n# 先创建一个用户\nmysql&gt; CREATE USER &#39;SunnyBear&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\n# 授权\n# 其中sunny.*代表赋予sunny数据库所有操作权限, 如果想赋予所有数据库权限, 可设置为*.*\n# 其中&#39;SunnyBear&#39;@&#39;%&#39;代表允许SunnyBear用户在任何ip登录, 当然也可以指定ip, 例如&#39;用户名称&#39;@&#39;ip地址&#39;\nmysql&gt; GRANT ALL PRIVILEGES ON sunny.* TO &#39;SunnyBear&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\n# 刷新权限\nFLUSH PRIVILEGES;\n\n配置成功之后可以使用连接工具尝试连接，我这里使用的是 Navicat，至此，单机版 MySQL 安装配置完成。\n\n一些命令\n# 启动mysql服务\nsystemctl start mysqld.service\n\n# 停止mysql服务\nsystemctl stop mysqld.service\n\n# 重启mysql服务\nsystemctl restart mysqld.service\n\n# 查看mysql服务当前状态\nsystemctl status mysqld.service\n\n# 设置mysql服务开机自启动\nsystemctl enable mysqld.service\n\n# 停止mysql服务开机自启动\nsystemctl disable mysqld.service\n\n\n\n6、修改配置文件\n修改hive-env.sh文件\n[root@bd04 conf]# vim hive-env.sh\n\nexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;jdk1.8.0_191\nexport HIVE_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;apache-hive-3.1.2-bin\nexport HADOOP_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;hadoop-3.2.0\n修改hive-site.xml\n\n\n\n\n\n\n\n\n\n在hive-site.xml文件中根据下面property中的name属性的值修改对应value的值，这些属性默认里面都是有的，所以都是修改对应的value的值即可\n[root@bd04 conf]# vim hive-site.xml \n&lt;property&gt;\n    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;&#x2F;name&gt;\n    &lt;value&gt;jdbc:mysql:&#x2F;&#x2F;bd04:3306&#x2F;hive?serverTimezone&#x3D;Asia&#x2F;Shanghai&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt; \n    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;&#x2F;name&gt; \n    &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;&#x2F;value&gt; \n&lt;&#x2F;property&gt; \n&lt;property&gt; \n    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;&#x2F;name&gt; \n    &lt;value&gt;root&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt; \n&lt;property&gt; \n    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;&#x2F;name&gt;\n    &lt;value&gt;admin&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt; \n    &lt;name&gt;hive.querylog.location&lt;&#x2F;name&gt; \n    &lt;value&gt;&#x2F;data&#x2F;hive_repo&#x2F;querylog&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt; \n&lt;property&gt; \n    &lt;name&gt;hive.exec.local.scratchdir&lt;&#x2F;name&gt; \n    &lt;value&gt;&#x2F;data&#x2F;hive_repo&#x2F;scratchdir&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt; \n&lt;property&gt; \n    &lt;name&gt;hive.downloaded.resources.dir&lt;&#x2F;name&gt;\n    &lt;value&gt;&#x2F;data&#x2F;hive_repo&#x2F;resources&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n\n\n\n\n\n\n\n\n\n\n注意:mysql驱动包的版本，要和我们安装的版本保持一致：mysql-connector-java-8.0.16.jar,这里需要注意mysql驱动需要放在hive下面的lib包下。\n[root@bd04 lib]# pwd\n&#x2F;opt&#x2F;moudle&#x2F;apache-hive-3.1.2-bin&#x2F;lib\n[root@bd04 lib]# ll | grep mysql\n-rw-r--r--. 1 root root  2293144 6月   2 15:39 mysql-connector-java-8.0.16.jar\n-rw-r--r--. 1 root root    10476 11月 16 2018 mysql-metadata-storage-0.12.0.jar\n\n7、修改core-site.xml的配置修改bigdata01中的core-site.xml，然后同步到集群中的另外两个节点上如果不增加这个配置，使用beeline连接hive的时候会报错\n[root@bd01 hadoop]# vim core-site.xml \n  &lt;property&gt;\n        &lt;name&gt;hadoop.proxyuser.root.hosts&lt;&#x2F;name&gt;\n        &lt;value&gt;*&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.proxyuser.root.groups&lt;&#x2F;name&gt;\n        &lt;value&gt;*&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n[root@bd01 hadoop]# xsync core-site.xml \nfname&#x3D;core-site.xml\npdir&#x3D;&#x2F;opt&#x2F;moudle&#x2F;hadoop-3.2.0&#x2F;etc&#x2F;hadoop\n--------------- bd01 ----------------\nsending incremental file list\n\nsent 50 bytes  received 12 bytes  124.00 bytes&#x2F;sec\ntotal size is 1,191  speedup is 19.21\n--------------- bd02 ----------------\nsending incremental file list\ncore-site.xml\n\nsent 592 bytes  received 47 bytes  426.00 bytes&#x2F;sec\ntotal size is 1,191  speedup is 1.86\n--------------- bd03 ----------------\nsending incremental file list\ncore-site.xml\n\nsent 592 bytes  received 47 bytes  426.00 bytes&#x2F;sec\ntotal size is 1,191  speedup is 1.86\n\n8、启动Hadoop集群[root@bd01 hadoop]# start-all.sh \nStarting namenodes on [bd01]\n上一次登录：四 6月  2 15:42:23 CST 2022从 192.168.126.1pts&#x2F;0 上\nStarting datanodes\n上一次登录：四 6月  2 15:46:26 CST 2022pts&#x2F;0 上\nStarting secondary namenodes [bd01]\n上一次登录：四 6月  2 15:46:29 CST 2022pts&#x2F;0 上\nStarting resourcemanager\n上一次登录：四 6月  2 15:46:34 CST 2022pts&#x2F;0 上\nStarting nodemanagers\n上一次登录：四 6月  2 15:46:40 CST 2022pts&#x2F;0 上\n[root@bd01 hadoop]# xcall jps\n----------bd01---------\n2518 SecondaryNameNode\n2215 NameNode\n2777 ResourceManager\n3118 Jps\n----------bd02---------\n1410 NodeManager\n1332 DataNode\n1564 Jps\n----------bd03---------\n1329 DataNode\n1563 Jps\n1406 NodeManager\n\n9、初始化Hive的Metastore[root@bd04 bin]# schematool -dbType mysql -initSchema\n\n如果发现如下报错\nCaused by: com.ctc.wstx.exc.WstxParsingException: Illegal character entity: expansion character (code 0x8\n at [row,col,system-id]: [3215,96,&quot;file:&#x2F;opt&#x2F;moudle&#x2F;apache-hive-3.1.2-bin&#x2F;conf&#x2F;hive-site.xml&quot;]\n        at com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:621)\n        at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:491)\n        at com.ctc.wstx.sr.StreamScanner.reportIllegalChar(StreamScanner.java:2456)\n        at com.ctc.wstx.sr.StreamScanner.validateChar(StreamScanner.java:2403)\n        at com.ctc.wstx.sr.StreamScanner.resolveCharEnt(StreamScanner.java:2369)\n        at com.ctc.wstx.sr.StreamScanner.fullyResolveEntity(StreamScanner.java:1515)\n        at com.ctc.wstx.sr.BasicStreamReader.nextFromTree(BasicStreamReader.java:2828)\n        at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1123)\n        at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3277)\n        at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3071)\n        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2964)\n        ... 15 more\n\n但是执行之后发现报错了，提示hive-site.xml文件中的第3215行内容有问题其实这个是原始配置文件本身就有的问题，最直接的就是把这一行直接删掉，删除之后的效果如下：其实就是把hive.txn.xlock.iow对应的description标签内容删掉，这样就可以了\n&lt;property&gt;\n    &lt;name&gt;hive.txn.xlock.iow&lt;&#x2F;name&gt;\n    &lt;value&gt;true&lt;&#x2F;value&gt;\n    &lt;description&gt;\n    &lt;&#x2F;description&gt;\n  &lt;&#x2F;property&gt;\n\n修改后再执行初始化命令，初始化Metastore\n[root@bd04 bin]# schematool -dbType mysql -initSchema\n#出现下面则说明初始化成功\nInitialization script completed\nschemaTool completed\n\n\n\n\n\n\n\n\n\n\n这样Hive就安装好了，注意了，目前针对Hive不需要启动任何进程\n","slug":"数据仓库Hive入门","date":"2022-06-01T08:23:04.000Z","categories_index":"Hive","tags_index":"Hive","author_index":"张春博"},{"id":"3e4c7b56240531255ad11affc0c50a94","title":"Hadoop搭建简易分布式集群","content":"使用三台机器创建Hadoop简易主从分布式集群，实现一个一主两从的Hadoop集群\n\nHadoop简易分布式集群搭建\n1. 环境准备规划三个虚拟机节点：bd01、bd02、bd03\nbd01 192.168.126.201\n\nbd02 192.168.126.202\n\nbd03 192.168.126.203\n\n\n\n\n\n\n\n\n\n\n注意：每个节点的基础环境都要先配置好，先把ip、hostname、firewalld、ssh免密码登录、JDK这些基础环境配置好。\nSSH免密配置：\n\n首先在bd01上执行ssh-keygen -t rsa,生产SSH密钥\n[root@bd01 ~]# ssh-keygen -t rsa\n[root@bd01 ~]# cd .ssh&#x2F;\n[root@bd01 .ssh]# ll\n-rw-------. 1 root root 1675 5月  31 16:37 id_rsa\n-rw-r--r--. 1 root root  391 5月  31 16:37 id_rsa.pub\n分别执行ssh-copy-id 到bd01、bd02、bd03\n[root@bd01 .ssh]# ssh-copy-id bd01\n[root@bd01 .ssh]# ssh-copy-id bd02\n[root@bd01 .ssh]# ssh-copy-id bd03\n\n2. 配置集群节点之间时间同步集群只要涉及到多个节点的就需要对这些节点做时间同步，如果节点之间时间不同步相差太多，会应该集群的稳定性，甚至导致集群出问题。\n首先在bigdata01节点上操作，使用ntpdate -u ntp.sjtu.edu.cn实现时间同步，但是执行的时候提示找不到ntpdata命令\n[root@bd01 .ssh]# ntpdate -u ntp.sjtu.edu.cn\n-bash: ntpdate: 未找到命令\n\n默认是没有ntpdate命令的，需要使用yum在线安装，bd01、bd02、bd03分别执行命令 yum install -y ntpdate\n[root@bd01 .ssh]# yum install -y ntpdate\n已加载插件：fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * extras: mirrors.aliyun.com\n * updates: mirrors.cn99.com\nbase                                                                            | 3.6 kB  00:00:00     \nextras                                                                          | 2.9 kB  00:00:00     \nupdates                                                                         | 2.9 kB  00:00:00     \n正在解决依赖关系\n--&gt; 正在检查事务\n---&gt; 软件包 ntpdate.x86_64.0.4.2.6p5-29.el7.centos.2 将被 安装\n--&gt; 解决依赖关系完成\n\n依赖关系解决\n\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n Package              架构                版本                                 源                 大小\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n正在安装:\n ntpdate              x86_64              4.2.6p5-29.el7.centos.2              base               87 k\n\n事务概要\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n安装  1 软件包\n\n总下载量：87 k\n安装大小：121 k\nDownloading packages:\nntpdate-4.2.6p5-29.el7.centos.2.x86_64.rpm                                      |  87 kB  00:00:00     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  正在安装    : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                                             1&#x2F;1 \n  验证中      : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                                             1&#x2F;1 \n\n已安装:\n  ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2                                                             \n\n完毕！\n\n然后手动执行ntpdate -u ntp.sjtu.edu.cn 确认是否可以正常执行\n[root@bd01 .ssh]# ntpdate -u ntp.sjtu.edu.cn\n31 May 16:58:43 ntpdate[1665]: adjust time server 202.118.1.81 offset 0.096553 sec\n\n\n\n\n\n\n\n\n\n\n建议把这个同步时间的操作添加到linux的crontab定时器中，每分钟执行一次\n[root@bd01 .ssh]# vim &#x2F;etc&#x2F;crontab \n* * * * * root &#x2F;usr&#x2F;sbin&#x2F;ntpdate -u ntp.sjtu.edu.cn\n\n3. 首先在bd01节点上安装hadoop\n解压hadoop安装包\n[root@bd01 hadoop-3.2.0]# tar -zxvf hadoop-3.2.0.tar.gz -C &#x2F;opt&#x2F;moudle&#x2F;\n[root@bd01 hadoop-3.2.0]# cd &#x2F;opt&#x2F;moudle&#x2F;\n[root@bd01 moudle]# ll\n总用量 0\ndrwxr-xr-x. 9 1001 1002 149 1月   8 2019 hadoop-3.2.0\ndrwxr-xr-x. 7   10  143 245 10月  6 2018 jdk1.8.0_191\n修改hadoop配置文件\n\n首先修改hadoop-env.sh文件，在文件末尾增加环境变量信息\n[root@bd01 hadoop]# vim hadoop-env.sh\nexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;jdk1.8.0_191\nexport HADOOP_LOG_DIR&#x3D;&#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop\n修改core-site.xml文件，注意fs.defaultFS属性中的主机名需要和主节点的主机名保持一致\n[root@bd01 hadoop]# vim core-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;bd01:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;&#x2F;data&#x2F;hadoop_repo&lt;&#x2F;value&gt;\n   &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改hdfs-site.xml文件，把hdfs中文件副本的数量设置为2(默认为3)，最多为2，因为现在集群中有两个从节点，还有secondaryNamenode进程所在的节点信息\n[root@bd01 hadoop]# vim hdfs-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n        &lt;value&gt;2&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;\n        &lt;value&gt;bd01:50090&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改mapred-site.xml，设置mapreduce使用的资源调度框架\n[root@bd01 hadoop]# vim mapred-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;\n        &lt;value&gt;yarn&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改yarn-site.xml，设置yarn上支持运行的服务和环境变量白名单\n\n\n\n\n\n\n\n\n\n注意，针对分布式集群在这个配置文件中还需要设置resourcemanager的hostname，否则nodemanager找不到resourcemanager节点。\n[root@bd01 hadoop]# vim yarn-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;\n        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;\n        &lt;value&gt;bd01&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改workers文件，增加所有从节点的主机名，一个一行\n[root@bd01 hadoop]# vim workers \nbd02\nbd03\n修改启动脚本\n修改start-dfs.sh，stop-dfs.sh这两个脚本文件，在文件前面增加如下内容\n[root@bd01 sbin]# vim start-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n[root@bd01 sbin]# vim stop-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n\n修改start-yarn.sh，stop-yarn.sh这两个脚本文件，在文件前面增加如下内容\n[root@bd01 sbin]# vim start-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n[root@bd01 sbin]# vim stop-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n\n\n\n4. 编写xcall和xsync脚本集群中有多台机器，配置启动集群每次都需要去每台机器上执行一遍相同的命令以及拷贝文件，为了简化操作，编写xcall脚本和xsync脚本\n\n\n\n\n\n\n\n\n\nxcall脚本功能：xcall + 命令，会在集群中的每台机器上都执行一遍此命令，并把结果输出\nxsycn脚本功能：xsync+ 文件/文件夹，会指定的文件/文件夹同步文件到集群中的每台机器中。\n\nxcall脚本\n#!&#x2F;bin&#x2F;bash\npcount&#x3D;$#\nif((pcount&#x3D;&#x3D;0));then\n        echo no args;\n        exit;\nfi\n\n#注释掉下面两行,不注释当前主机会执行两次命令\n#echo -------------localhost----------\n#$@\nfor((host&#x3D;1; host&lt;&#x3D;3; host++)); do\n        echo ----------bd0$host---------\n        ssh bd0$host $@\ndone\n\n功能验证：\n[root@bd01 sbin]# xcall pwd\n----------bd01---------\n&#x2F;root\n----------bd02---------\n&#x2F;root\n----------bd03---------\n&#x2F;root\nxsync脚本\n#!&#x2F;bin&#x2F;bash\n# $#：表示传递给脚本或函数的参数个数。\n#1 获取输入参数个数，如果没有参数，直接退出\npcount&#x3D;$#\nif((pcount&#x3D;&#x3D;0)); then\necho no args;\nexit;\nfi\n\n#2 获取文件名称\np1&#x3D;$1\nfname&#x3D;&#96;basename $p1&#96;\necho fname&#x3D;$fname\n\n#3 获取上级目录到绝对路径\npdir&#x3D;&#96;cd -P $(dirname $p1); pwd&#96;\necho pdir&#x3D;$pdir\n\n#4 获取当前用户名称\nuser&#x3D;&#96;whoami&#96;\n\n#5 循环\nfor((host&#x3D;1; host&lt;4; host++)); do\n       echo --------------- bd0$host ----------------\n       rsync -rvl $pdir&#x2F;$fname $user@bd0$host:$pdir\ndone\n\n功能验证\n[root@bd01 moudle]# mkdir xysnc-test\n[root@bd01 moudle]# xsync xysnc-test&#x2F;\nfname&#x3D;xysnc-test\npdir&#x3D;&#x2F;opt&#x2F;moudle\n--------------- bd01 ----------------\nsending incremental file list\n\nsent 59 bytes  received 17 bytes  50.67 bytes&#x2F;sec\ntotal size is 0  speedup is 0.00\n--------------- bd02 ----------------\nsending incremental file list\nxysnc-test&#x2F;\n\nsent 62 bytes  received 20 bytes  164.00 bytes&#x2F;sec\ntotal size is 0  speedup is 0.00\n--------------- bd03 ----------------\nsending incremental file list\nxysnc-test&#x2F;\n\nsent 62 bytes  received 20 bytes  164.00 bytes&#x2F;sec\ntotal size is 0  speedup is 0.00\n\n5. 把bd01节点上将修改好配置的安装包拷贝到其他两个从节点,并在在bd01节点上格式化HDFS\n同步hadoop到bd02和bd03\n[root@bd01 moudle]# xsync hadoop-3.2.0&#x2F;\n在bd01节点上格式化HDFS\n[root@bd01 hadoop-3.2.0]# bin&#x2F;hdfs namenode -format\n\n如果在后面的日志信息中能看到这一行，则说明namenode格式化成功。\n2022-05-31 21:15:15,324 INFO common.Storage: Storage directory &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name has been successfully formatted.\n\n6. 启动集群在bd01上执行命令\n[root@bd01 hadoop-3.2.0]# sbin&#x2F;start-all.sh \nStarting namenodes on [bd01]\n上一次登录：二 5月 31 21:22:48 CST 2022pts&#x2F;0 上\nStarting datanodes\n上一次登录：二 5月 31 21:23:47 CST 2022pts&#x2F;0 上\nbd03: WARNING: &#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop does not exist. Creating.\nStarting secondary namenodes [bd01]\n上一次登录：二 5月 31 21:23:49 CST 2022pts&#x2F;0 上\nStarting resourcemanager\n上一次登录：二 5月 31 21:23:55 CST 2022pts&#x2F;0 上\nStarting nodemanagers\n上一次登录：二 5月 31 21:24:00 CST 2022pts&#x2F;0 上\n\n7. 验证集群使用xcall命令操作集群，验证hadoop集群是否搭建成功\n[root@bd01 hadoop]# xcall jps\n----------bd01---------\n5520 ResourceManager\n5267 SecondaryNameNode\n5879 Jps\n4973 NameNode\n----------bd02---------\n2402 DataNode\n2516 NodeManager\n2635 Jps\n----------bd03---------\n2022 DataNode\n2137 NodeManager\n2235 Jps\n\n8. 停止集群[root@bd01 hadoop]# stop-all.sh \nStopping namenodes on [bd01]\n上一次登录：二 5月 31 21:24:03 CST 2022pts&#x2F;0 上\nStopping datanodes\n上一次登录：二 5月 31 21:26:35 CST 2022pts&#x2F;0 上\nStopping secondary namenodes [bd01]\n上一次登录：二 5月 31 21:26:36 CST 2022pts&#x2F;0 上\nStopping nodemanagers\n上一次登录：二 5月 31 21:26:39 CST 2022pts&#x2F;0 上\nStopping resourcemanager\n上一次登录：二 5月 31 21:26:42 CST 2022pts&#x2F;0 上\n\nHadoop集群搭建成功！\n","slug":"Hadoop搭建简易分布式集群","date":"2022-05-31T07:14:45.000Z","categories_index":"Hadoop","tags_index":"Hadoop","author_index":"张春博"},{"id":"7e9c0ed522e9f463cbadca3b64226a03","title":"Elasticsearch的介绍与安装","content":"Elasticsearch是一个分布式的开源搜索和分析引擎，适用于所有类型的数据，包括文本、数字、地理空间、结构化和非结构化数据。Elasticsearch是在Lucene的基础上开发而成，由Elasticsearch N.V(即现在的Elastic)于2010年首次发布。Elasticsearch以其简单的REST风格的API、分布式特性、速度和可扩展性而闻名，是Elastic Stack的核心组件。\n\n什么是ELK？Elastic Stack通常被称为ELK Stack(代指Elasticsearch、LogStash和Kibana),Elastic Stack是适用于数据采集、充实、存储、分析和可视化的一组开源工具。目前Elastic Stack包括一系列丰富的轻量型数据采集代理，这些代理统称为Beats，可用来向Elasticsearch发送数据。\nLucene vs Solr vs Elasticsearch\n都使用倒排序索引\nLucene是一个类库，基于Java的全文搜索引擎。\nSolr基于Lucene构建的开源引擎，使用Java封装。\nES基于Lucene,高扩展性，支持PB级别的搜索。\n\n\n\n\n\n\n\n\n\n\n正排索引和倒排索引\n正排索引：文档ID作为索引，以文档内容作为记录。但是这样检索关键词的时候很费力，要一个文档一个文档的遍历一遍。\n\n倒排索引：将单词或记录作为索引，将文档ID作为记录，这样便可以方便地通过单词或记录查找到其所在的文档。\n\nElasticsearch安装\n下载Elasticsearch(点击进入Elasticsearch下载页)，选择Linux版本下载。\n\n上传到服务器，进入Elasticsearch的目录下\ntar -zxvf elasticsearch-7.4.2-linux-x86_64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;\n\n\n\n\n\n\n\n\n\n\nElasticsearch的目录结构：\nbin：可执行文件包括elasticsearch启动节点、elasticsearch-plugin安装插件。\nconfig：配置文件\njdk: Elasticsearch依赖的Java环境\nlib：依赖的类库\nlogs：日志文件\nmodules：和ES有关的模块\nplugins: ES的自定义插件\n\n进入Elasticsearch的解压目录内，创建data文件夹\ncd &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;\nmkdir data\n进入config目录进行配置，对elasticsearch.yml进行修改\ncd config&#x2F;\nvim elasticsearch.yml \n配置cluster.name，cluster.name为ES集群名称\ncluster.name: joker-elasticsearch\n配置node.name，node.name为当前ES节点名称\nnode.name: es-node1\n配置path.data和path.logs，path.data为ES数据源路径，path.logs为ES的log日志路径\n# Path to directory where to store the data (separate multiple       locations by comma):\n#\npath.data: &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;data\n#\n# Path to log files:\n#\npath.logs: &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;logs\n配置network.host，network.host为绑定ip地址\n# Set the bind address to a specific IP (IPv4 or IPv6):\nnetwork.host: 0.0.0.0\n配置luster.initial_master_nodes\ncluster.initial_master_nodes: [&quot;es-node1&quot;]\n\n\n\n\n\n\n\n\n\n\n修改jvm.options文件,可以配置ES的运行内存\n\n进入bin目录，启动Elasticsearch\ncd bin&#x2F;\n.&#x2F;elasticsearch -d\n\n\n\n\n\n\n\n\n\n\n在启动Elasticsearch的时候需注意一下几点：\n\n不能以root用户启动Elasticsearch，否则会报错。\n\n启动Elasticsearch报错max virtual memory areas vm.max_map_count    [65530] is too low, increase to at least [262144],\n\n解决方案：修改sysctl.conf文件\n\nvim &#x2F;etc&#x2F;sysctl.conf\n\n\n修改vm.max_map_count的内存大小\n\nvm.max_map_count&#x3D;262145\n\n\n使用sysctl -p命令刷新配置\n\nsysctl -p\n\n以上就是Elasticsearch的基本概念以及安装，不同版本可能有细微差别，如安装出现问题可参考官方文档解决。\n","slug":"Elasticsearch的介绍与安装","date":"2022-01-18T03:05:24.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"张春博"},{"id":"29689429ad8148e438d5ca2aa7b9d913","title":"2023年3月03工作周报","content":"手机银行自研工作：\n在建需求8单：1单灰度发布，1单准生产测试，3单系统测试，3单开发编码中.\n需求-巡视】ALM00026197-关于手机银行利率查询、服务资费更换跳转至新官网页面的需求：准生产测试\n【项目】ALM00024828-智能营销系统移动端新增产品海报分享及外拓营销的项目一批次：灰度发布\n\n手机银行专题工作\n2月份专题：完成三次灰度发布\n\n财富启航3.0：\n\nALM00025908-手机银行财富频道改版需求：设计阶段\nALM00026139-手机银行新增智选理财功能：需求下发\nALM00025909-手机银行新增财富陪伴：需求下发\n\n\n手机银行8.0：\n\nALM00025943-手机银行【我的】页签改版需求：开发编码\nALM00025919-关于手机银行首页优化改版的需求（一批次）：设计阶段\n\n\n\n手机银行敏捷小组重点工作\n本周新增1单故障；新增0单需求\n\n","slug":"2023年3月03工作周报","date":"2023-03-03T10:45:00.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"aaf1c992334b402e2ec2402b90704435","title":"2023年2月24工作周报","content":"手机银行专题需求\n在建需求8单：2单准生产，2单系统测试，4单开发编码中\n【需求-巡视】ALM00026197-关于手机银行利率查询、服务资费更换跳转至新官网页面的需求：系统测试\n【项目】ALM00024828-智能营销系统移动端新增产品海报分享及外拓营销的项目一批次：准生产测试\n2月份专题：完成灰度发布\n完成22年/23年手机银行发布日历\n线上财富频道 3.0\n手机银行优化改版\n\n手机银行敏捷开发小组重点工作\n本周新增1单故障；新增1单需求\n\n","slug":"2023年2月24工作周报","date":"2023-02-24T12:14:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"a8af3c5bc0e2f5651ddfdce68d98b2bf","title":"mPaas国密改造—MGS切换国密加密","content":"\n因当前国家信息安全监管总局对金融类App监管要求，涉及到数据安全通信加密算法必须要使用国密的规定。众多使用mPaaS框架的银卡金融客户，因早期大多数都是在网关配置的RSA加密或者ECC加密算法，当接到监管要求后，都要更改网关加密算法为国密，因需求众多mPaaS团队也为此开发了网关同时兼容多个加密方式的功能，去解决客户侧因更换加密算法造成的种种不便和问题。\n\n背景因当前国家信息安全监管总局对金融类App监管要求，涉及到数据安全通信加密算法必须要使用国密的规定。众多使用mPaaS框架的银卡金融客户，因早期大多数都是在网关配置的RSA加密或者ECC加密算法，当接到监管要求后，都要更改网关加密算法为国密，因需求众多mPaaS团队也为此开发了网关同时兼容多个加密方式的功能，去解决客户侧因更换加密算法造成的种种不便和问题。\n以下分别对控制台网关配置和客户端配置，整理更换加密算法方案。初次配置网关加密和客户端配置，参考文档：https://help.aliyun.com/document_detail/72752.html。\n服务端开发平台\n打开移动开发平台-&gt;移动网关-&gt;网关管理：\n\n\n这时更换国密，需要提前准备一对已生成的SM2 公、私钥，详细密钥生成方法参考：https://help.aliyun.com/document_detail/64281.htm。\n\n在控制台-网关管理下，先关闭数据加密，再立刻开启数据加密，这是会出现重新选择加密算法和填写对应密钥的弹窗，如下图。\n\n\n将SM2的私钥按正确格式填写到输入框内，点击提交。之后就能在这里看到已经配置好的两种加密方式：\n\n\n\n介此，网关更换密钥操作已完成。\n\n\n\n\n\n\n\n\n\n步骤3中必须要先关闭再开启，此时要快速操作，所以请务必先提前生成好对应的SM2公、私钥，且保证正确性和正确格式。\n客户端IOS端\niOS客户端的加密方式和公钥是配置在info.plist下的，详情见图：\n\n\n此时将已生成好的SM2公钥按正确格式替换上述info.plist里PubKey的value，加密算法更改为SM2。\n\n\n\n介此 iOS端加密方式和公钥也已更换完毕。\nAndroid端\nAndroid 端的加密方式和公钥是配置在mpaas_netconfig.properties 文件下的，如图：\n\n\n此时将已生成好的SM2公钥按正确格式替换上述mpaas_netconfig.properties 里的对应value，更换后如下图：\n\n\n\n介此 Android 端加密方式和公钥已更换完毕。\n结束语此时服务端和客户端均已更换加密方式完毕，旧版App依然可以正常访问网关，新版App也是可以正常访问网关的，后续需要等待旧版App用户完全升级到新版App后，修改掉网关旧的加密方式即可，当然一直保留也可以的。\n","slug":"mPaas国密改造—MGS切换国密加密","date":"2023-02-17T11:14:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"9d83de4a8ee48d56851bf8746f3a11fa","title":"2023年2月17工作周报","content":"手机银行自研工作：\n在建需求7单：1单完成上线，2单系统测试，2单开发编码中，2单需求分析中。\n\n手机银行专题工作\n1月份专题：完成强制更新转正式发布。\n2月份专题：完成2月份版本一次灰度。\n完成22年/23年手机银行发布日历\n\n手机银行敏捷小组重点工作\n本周新增3单故障；新增1单需求\n\n","slug":"2023年2月17工作周报","date":"2023-02-17T09:31:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"3dc79052ad833c97c9d4021a5676da91","title":"手机银行新客专题需求月度版本工作记录","content":"需求背景新客户登录手机银行，现生产针对新客户进行了相关功能引导，现为了挺高新客经营成功率，将现有引导进行优化，可引导客户签约相关核心业务；\n2.为了更好的营销客户，在相关功能、应用图标、页面根据智能营销客户标签配置不同的引导内容。\n需求计划\n\n\n\n\n\n\n\n\n需求设计：2022/8/31-2022/9/16 9.7号提供接口\n开发联调：2022/9/19-2022/11/11\n内部测试：2022/11/14-2022/11/25\n提交测试：2022/11/25\n系统测试：2022/11/28-2022/12/23\n准生产测试：2022/12/26-2023/1/6\n业务测试：2022/12/1-2022/12/30\n设计审评阶段问题\n\n\n\n\n\n\n\n\n\n智能营销：用户标签表、码值表是否需要修改视图\n智能营销：确认一下生产的标签正确性\n企业知识平台：修改视图\n企业知识平台：先上老的，后期统一迁移\n中台：根据灰度标志判断\n中台：增加脚本及影响范围，明确是否可回退\n中台：明确一下新增的、修改的接口\n中台：明确一下需要压测的接口\n中台：修改弹窗内容后id不会改变\n中台：弹窗只展示一个（最新的）\n中台内管：老版的不能修改，导航标签重新修改、内管应用标签\n中台内管：弹窗删除策略后，\n\n工作总结\n新客改造涉及手机银行首页气泡改版以及提示语修改，需重构中台内管，由于手机银行月度版本发布均已灰度形式发布，但中台内管无灰度机制，所以中台内管需提供灰度支持，与业务沟通交流后，采用中台内管新起气泡管理功能，其数据使用新表记录解决此问题。\n\n新客改造需手机银行记录用户气泡点击行为，由于气泡内容由中台内管可配置，所以需要考虑用户气泡点击事件的数据删除功能，如数据不删除会导致手机银行前置数据库存在垃圾数据并会随着时间逐渐积累增大，后经与开发讨论，采用当中台内管重置气泡行为的时候中台内管访问前置数据库，对用户行为记录进行删除。\n\n新客需智能营销用户标签数据支持，新客上线之前需智能营销和企业知识平台提前上线进行铺数准备。\n\n\n","slug":"手机银行新客专题需求月度版本工作记录","date":"2023-02-10T12:14:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"b7a7dd94c658161972f0a073f2293e27","title":"2023年2月10工作周报","content":"手机银行自研工作：\n在建需求6单：2单系统测试，4单开发编码中。\n\n手机银行专题工作\n1月份专题：1、完成应用市场的发布；2、完成转正式。\n2月份专题：准生产测试。\n完善22年/23年手机银行发布日历\n\n手机银行敏捷小组重点工作\n本周新增1单故障；新增1单需求\n\n","slug":"2023年2月10工作周报","date":"2023-02-10T09:31:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"bfc305b99c5cb0bd679dca33789b927d","title":"手机银行Android集成mPaas模式PB升级AAR记录","content":"mPaas目前接入方式有两种，分别是原生AAR模式和组件化方式（Portal&amp;Bundle），AAR模式为后期mPaas推出，手机银行4.0采用的为PB模式。\n原生 AAR 方式原生 AAR 接入方式 是指采用原生 Android AAR 打包方案，更贴近 Android 开发者的技术栈。开发者无需了解 mPaaS 相关的打包知识，通过 mPaaS Android Studio 插件，或者直接通过 Maven 的 pom 和 bom，即可将 mPaaS 集成到开发者的项目中来。该方式降低了开发者的接入成本，能够让开发者更轻松地使用 mPaaS，适合对 组件化（Portal&amp;Bundle）接入方式 没有特别需求，想快速使用 mPaaS 能力的客户。\n\n\n\n\n\n\n\n\n\n说明 \n原生 AAR 接入方式从 10.1.68 起开始支持。\n组件化方式（Portal&amp;Bundle）组件化方式 是指 mPaaS 基于 OSGi（Open Service Gateway Initiative，开放服务网关倡议）技术将一个 App 划分成业务独立的一个或多个 Bundle 工程以及一个 Portal 工程的框架。mPaaS 会对每个 Bundle 工程的生命周期和依赖加以管理，使用 Portal 工程把所有的 Bundle 工程包合并成一个可运行的 .apk 包。该方式适用于大型多人并行开发项目。使用 组件化方式，需要引入 mPaaS gradle 打包工具，对 gradle 版本以及com.android.tools.build:gradle 版本有一定的要求。\n如何选择接入方式如果使用 mPaaS 需要像使用其他 SDK 一样简单接入并使用，推荐使用 原生 AAR 方式。如果使用 mPaaS 来重构您的项目需要引入大规模并行研发的理念，推荐使用 组件化方式 。\n接入方式对比\n\n\n\n原生 AAR 接入\n组件化接入\n\n\n\n来源\nGoogle 官方接入方式。\n源自支付宝。\n\n\n打包速度\n三者之中打包最慢，和原生接入一模一样。\n打包速度快，打包时间分散。\n\n\n项目组成方式\nApp module 和 library module。\nPortal（一个 App 的壳）和 Bundle（各种业务组件）。\n\n\n依赖 Gradle 版本\n可以升级到官方最新版本，目前是 Gradle 7.x。\n4.4/6.3。开发者不可擅自升级。\n\n\n依赖 AGP1 工具链\n可以升级到官方最新版本，目前是 AGP 7.0.3。\nAGP 3.0.1/3.5.x（开发者不可擅自升级）。\n\n\nAndroid Support Library\n可使用。\n必须使用 mPaaS 提供的版本（23），开发者不可擅自升级。\n\n\nAndroid X\n完整支持2\n不支持\n\n\ndatabinding\n完整支持\nv1\n\n\nkotlin\n完整支持\n尽量不要使用\n\n\n手机银行由PB模式升级为AAR模式\n首先替换gradle\n\ndistributionUrl=https://services.gradle.org/distributions/gradle-5.6.4-all.zip\n\nclasspath ‘com.android.tools.build:gradle:3.4.2’classpath ‘com.android.boost.easyconfig:easyconfig:2.6.0’\n\n\n\napply plugin: ‘com.alipay.apollo.optimize’\n\nid ‘com.alipay.apollo.baseline.config’\n\n去除所有的alipay的插件\n\napplication和library\n\n\n增加maven管理，目前打包到本地maven仓库，远程maven仓库目前还未申请下来\n\n配置maven_push.gradle脚本\n\n当前工程配置uploadArchives上传aar到maven仓库\n\n\n\n\n\n\n\n\n\n 其他注意点：\n\n1.去除MockLauncherActivityAgent和MockLauncherApplicationAgent，需要将这两个里面的逻辑移植\n\n将登录模块和h5模块解耦（目前手机银行登录模块和H5模块存在相互引用的问题）\n\n梳理手机银行app启动逻辑（长按应用图标快捷方式、分享启动手机银行等），分析改造影响\n\n\n\n\n","slug":"手机银行Android集成mPaas模式PB升级AAR记录","date":"2023-02-03T12:14:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"f65eea67ff289535800c5f32ff421958","title":"2023年2月03工作周报","content":"手机银行自研工作：\n在建需求7单：1单完成上线，2单系统测试，2单开发编码中，2单需求分析中。\n【需求-紧急】ALM00025739-关于手机银行隐私协议更新的需求：完成上线\n\n手机银行专题工作\n1月份专题：完成三次灰度的发布。\n2月份专题：确定发布范围。\n完成22年/23年手机银行发布日历\n\n手机银行敏捷小组重点工作\n本周新增4单故障；新增1单需求\n\n","slug":"2023年2月03工作周报","date":"2023-02-03T09:31:10.000Z","categories_index":"工作","tags_index":"工作日志","author_index":"张春博"},{"id":"bb0b195ced0db413665f5bd6467e3504","title":"Hadoop搭建伪分布式集群","content":"\nHadoop伪分布式集群即在一台Linux机器上部署Hadoop集群，通过开通不同的端口来实现相应集群搭建。\n\nHadoop伪分布式集群安装\n这张图代表是一台Linux机器，也可以称为是一个节点，上面安装的有JDK环境\n最上面的是Hadoop集群会启动的进程，其中NameNode、SecondaryNameNode、DataNode是HDFS服务的进程，ResourceManager、NodeManager是YARN服务的进程，MapRedcue在这里没有进程，因为它是一个计算框架，等Hadoop集群安装好了以后MapReduce程序可以在上面执行。\n配置基础环境\n\n\n\n\n\n\n\n\n静态ip配置、hostname配置、firewalld关闭、ssh免密登录、JDK\n安装Hadoop\n首先把下载好的hadoop安装包上传到/opt/software文件夹下\n[root@bigdata-01 software]# ll\n总用量 524788\n-rw-r--r--. 1 root root 345625475 5月  30 14:15 hadoop-3.2.0.tar.gz\n-rwxr-xr-x. 1 root root 191753373 1月  29 2021 jdk-8u191-linux-x64.tar.gz\n解压Hadoop压缩包\ntar -zxvf hadoop-3.2.0.tar.gz -C &#x2F;opt&#x2F;moudle&#x2F;\n[root@bigdata-01 software]# cd &#x2F;opt&#x2F;moudle&#x2F;\n[root@bigdata-01 moudle]# ll\n总用量 0\ndrwxr-xr-x. 9 1001 1002 149 1月   8 2019 hadoop-3.2.0\ndrwxr-xr-x. 7   10  143 245 10月  6 2018 jdk1.8.0_191\n修改Hadoop的配置文件\n\n\n\n\n\n\n\n\n\n主要修改以下文件：\nhadoop-env.sh\ncore-site.xml\nhdfs-site.xml\nmapred-site.xml\nyarn-site.xml workers\n\n首先修改 hadoop-env.sh 文件，增加环境变量信息，添加到hadoop-env.sh 文件末尾即可。\n\n\n\n\n\n\n\n\n\nJAVA_HOME：指定java的安装位置\nHADOOP_LOG_DIR：hadoop的日志的存放目录\n[root@bigdata-01 hadoop]# vim hadoop-env.sh\n# For example, to limit who can execute the namenode command,\n# export HDFS_NAMENODE_USER&#x3D;hdfs\n\nexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;jdk1.8.0_191\nexport HADOOP_LOG_DIR&#x3D;&#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop\n修改core-site.xml 文件\n\n\n\n\n\n\n\n\n\n注意 fs.defaultFS 属性中的主机名需要和你配置的主机名保持一致\n[root@bigdata-01 hadoop]# vim core-site.xml \n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;bigdata-01:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;&#x2F;data&#x2F;hadoop_repo&lt;&#x2F;value&gt;\n   &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改hdfs-site.xml文件，把hdfs中文件副本的数量设置为1，因为现在伪分布集群只有一个节点\n[root@bigdata-01 hadoop]# vim hdfs-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n        &lt;value&gt;1&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改mapred-site.xml，设置mapreduce使用的资源调度框架\n[root@bigdata-01 hadoop]# vim mapred-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;\n        &lt;value&gt;yarn&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改yarn-site.xml，设置yarn上支持运行的服务和环境变量白名单\n[root@bigdata-01 hadoop]# vim yarn-site.xml\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;\n   &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改workers，设置集群中从节点的主机名信息，在这里就一台集群，所以就填写bigdata-01即可\n[root@bigdata-01 hadoop]# vim workers \nbigdata-01\n\n\n格式化HDFS\n[root@bigdata-01 hadoop]# hdfs namenode -format\n\n2022-05-30 15:16:10,058 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n2022-05-30 15:16:10,060 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n2022-05-30 15:16:10,060 INFO util.GSet: VM type       &#x3D; 64-bit\n2022-05-30 15:16:10,060 INFO util.GSet: 0.029999999329447746% max memory 235.9 MB &#x3D; 72.5 KB\n2022-05-30 15:16:10,060 INFO util.GSet: capacity      &#x3D; 2^13 &#x3D; 8192 entries\n2022-05-30 15:16:10,220 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1971366973-192.168.126.200-1653894970205\n2022-05-30 15:16:10,231 INFO common.Storage: Storage directory &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name has been successfully formatted.\n2022-05-30 15:16:10,244 INFO namenode.FSImageFormatProtobuf: Saving image file &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 using no compression\n2022-05-30 15:16:10,381 INFO namenode.FSImageFormatProtobuf: Image file &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\n2022-05-30 15:16:10,391 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;&#x3D; 0\n2022-05-30 15:16:10,398 INFO namenode.NameNode: SHUTDOWN_MSG: \n&#x2F;************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at bigdata-01&#x2F;192.168.126.200\n************************************************************&#x2F;\n\n如果能看到successfully formatted这条信息就说明格式化成功了。\n如果提示错误，一般都是因为配置文件的问题，当然需要根据具体的报错信息去分析问题。\n\n\n\n\n\n\n\n\n\n注意：格式化操作只能执行一次，如果格式化的时候失败了，可以修改配置文件后再执行格式化，如果格式化成功了就不能再重复执行了，否则集群就会出现问题。\n如果确实需要重复执行，那么需要把/data/hadoop_repo目录中的内容全部删除，再执行格式化\n\n启动伪分布集群\n\n使用sbin目录下的start-all.sh脚本\n[root@bigdata-01 hadoop]# start-all.sh \nStarting namenodes on [bigdata-01]\nERROR: Attempting to operate on hdfs namenode as root\nERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\nStarting datanodes\nERROR: Attempting to operate on hdfs datanode as root\nERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.\nStarting secondary namenodes [bigdata-01]\nERROR: Attempting to operate on hdfs secondarynamenode as root\nERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.\nStarting resourcemanager\nERROR: Attempting to operate on yarn resourcemanager as root\nERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.\nStarting nodemanagers\nERROR: Attempting to operate on yarn nodemanager as root\nERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.\n\n解决方案如下：\n修改sbin目录下的start-dfs.sh，stop-dfs.sh这两个脚本文件，在文件前面增加如下内容\n[root@bigdata-01 sbin]# vim start-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n[root@bigdata-01 sbin]# vim stop-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n\n修改sbin目录下的start-yarn.sh，stop-yarn.sh这两个脚本文件，在文件前面增加如下内容\n[root@bigdata-01 sbin]# vim start-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n[root@bigdata-01 sbin]# vim stop-yarn.sh\nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n\n再次启动Hadoop\n[root@bigdata-01 sbin]# start-all.sh \nStarting namenodes on [bigdata-01]\n上一次登录：一 5月 30 14:59:58 CST 2022从 192.168.126.1pts&#x2F;3 上\nStarting datanodes\n上一次登录：一 5月 30 15:30:52 CST 2022pts&#x2F;3 上\nStarting secondary namenodes [bigdata-01]\n上一次登录：一 5月 30 15:30:56 CST 2022pts&#x2F;3 上\nStarting resourcemanager\n上一次登录：一 5月 30 15:31:02 CST 2022pts&#x2F;3 上\nStarting nodemanagers\n上一次登录：一 5月 30 15:31:10 CST 2022pts&#x2F;3 上\n\n\n验证集群进程信息\n执行jps命令可以查看集群的进程信息，去掉Jps这个进程之外还需要有5个进程才说明集群是正常启动的\n[root@bigdata-01 sbin]# jps\n2689 DataNode\n3159 ResourceManager\n3287 NodeManager\n3623 Jps\n2921 SecondaryNameNode\n2557 NameNode\n\n还可以通过webui界面来验证集群服务是否正常\n\nHDFS webui界面：http://192.168.126.200:9870\nYARN webui界面：http://192.168.126.200:8088\n\n\n停止集群\n如果修改了集群的配置文件或者是其它原因要停止集群，可以使用下面命令\n[root@bigdata-01 sbin]# stop-all.sh \nStopping namenodes on [bigdata-01]\n上一次登录：一 5月 30 15:31:12 CST 2022pts&#x2F;3 上\nStopping datanodes\n上一次登录：一 5月 30 15:35:14 CST 2022pts&#x2F;3 上\nStopping secondary namenodes [bigdata-01]\n上一次登录：一 5月 30 15:35:17 CST 2022pts&#x2F;3 上\nStopping nodemanagers\n上一次登录：一 5月 30 15:35:20 CST 2022pts&#x2F;3 上\nStopping resourcemanager\n上一次登录：一 5月 30 15:35:24 CST 2022pts&#x2F;3 上\n\n","slug":"Hadoop搭建伪分布式集群","date":"2022-05-30T06:07:49.000Z","categories_index":"Hadoop","tags_index":"Hadoop","author_index":"张春博"},{"id":"18af339b30adc2c46fa137e5f29a4b24","title":"ES 之分词与内置分词器","content":"分词器是从一串文本中切分一个个的词条，并对每个词条进行标准化。\n\n什么是分词？把文本转换为一个个的单词，分词称之为analysis。es默认只对英文语句做分词，中文不支持，每个中文字都会被拆分为独立的个体。\n\n英文分词：I study in imooc.com\n中文分词：我在慕课网学习\n\nPOST &#x2F;_analyze\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;text&quot;: &quot;text文本&quot;\n&#125;\nPOST &#x2F;my_doc&#x2F;_analyze\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;field&quot;: &quot;name&quot;,\n    &quot;text&quot;: &quot;text文本&quot;\n&#125;\n\nes内置分词器\nstandard：默认分词，单词会被拆分，大小会转换为小写。\nsimple：按照非字母分词。大写转为小写。\nwhitespace：按照空格分词。忽略大小写。\nstop：去除无意义单词，比如the/a/an/is…\nkeyword：不做分词。把整个文本作为一个单独的关键词。\n\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;text&quot;: &quot;My name is Peter Parker,I am a Super Hero. I don&#39;t like the Criminals.&quot;\n&#125;\n\n","slug":"ES 之分词与内置分词器","date":"2022-02-16T12:23:29.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"张春博"},{"id":"e6af55037cba3fe2cceb0e9fb27dac27","title":"Elasticsearch关于 REST API的使用介绍","content":"Elasticsearch提供了大量的REST api来集成、查询和管理数据。下面将在这篇文章中介绍一些经常使用的REST API。\n\n一、集群健康集群健康 | Elasticsearch: 权威指南 | Elastic\nGET &#x2F;_cluster&#x2F;health\n\n和 Elasticsearch 里其他 API 一样，cluster-health 会返回一个 JSON 响应。这对自动化和告警系统来说，非常便于解析。响应中包含了和你集群有关的一些关键信息：\n&#123;\n    &quot;cluster_name&quot;: &quot;joker-elasticsearch&quot;,\n    &quot;status&quot;: &quot;yellow&quot;,\n    &quot;timed_out&quot;: false,\n    &quot;number_of_nodes&quot;: 1,\n    &quot;number_of_data_nodes&quot;: 1,\n    &quot;active_primary_shards&quot;: 8,\n    &quot;active_shards&quot;: 8,\n    &quot;relocating_shards&quot;: 0,\n    &quot;initializing_shards&quot;: 0,\n    &quot;unassigned_shards&quot;: 3,\n    &quot;delayed_unassigned_shards&quot;: 0,\n    &quot;number_of_pending_tasks&quot;: 0,\n    &quot;number_of_in_flight_fetch&quot;: 0,\n    &quot;task_max_waiting_in_queue_millis&quot;: 0,\n    &quot;active_shards_percent_as_number&quot;: 72.72727272727273\n&#125;\n\n响应信息中最重要的一块就是 status 字段。状态可能是下列三个值之一：\ngreen\n所有的主分片和副本分片都已分配。你的集群是 100% 可用的。\nyellow\n所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。\nred\n至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。\ngreen/yellow/red 状态是一个概览你的集群并了解眼下正在发生什么的好办法。剩下来的指标给你列出来集群的状态概要：\n\nnumber_of_nodes 和 number_of_data_nodes 这个命名完全是自描述的。\nactive_primary_shards 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。\nactive_shards 是涵盖了所有索引的_所有_分片的汇总值，即包括副本分片。\nrelocating_shards 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。\ninitializing_shards 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing 状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从 initializing 状态开始。\nunassigned_shards 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片）。\n\n二、索引相关2.1 创建索引PUT &#x2F;index_demo\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;index&quot;: &#123;\n            &quot;number_of_shards&quot;: &quot;2&quot;,\n            &quot;number_of_replicas&quot;: &quot;0&quot;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nnumber_of_shards : 分片数\nnumber_of_replicas : 副本数\n\n2.2 删除索引DELETE &#x2F;index_demo\n\n2.3 查看索引GET &#x2F;_cat&#x2F;indices?v\n\n三、mappings 自定义创建映射3.1 创建索引的同时创建mappingsPUT &#x2F;index_mappings\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;index&quot;: &#123;\n            &quot;number_of_shards&quot;: &quot;3&quot;,\n            &quot;number_of_replicas&quot;: &quot;0&quot;\n        &#125;\n    &#125;,\n    &quot;mappings&quot;: &#123;\n        &quot;properties&quot;: &#123;\n            &quot;realname&quot;: &#123;\n            \t&quot;type&quot;: &quot;text&quot;,\n            \t&quot;index&quot;: true\n            &#125;,\n            &quot;username&quot;: &#123;\n            \t&quot;type&quot;: &quot;keyword&quot;,\n            \t&quot;index&quot;: false\n            &#125;,\n            &quot;id&quot;: &#123;\n        \t    &quot;type&quot;: &quot;long&quot;\n            &#125;,\n            &quot;age&quot;: &#123;\n            \t&quot;type&quot;: &quot;integer&quot;\n            &#125;,\n            &quot;nickname&quot;: &#123;\n                &quot;type&quot;: &quot;keyword&quot;\n            &#125;,\n            &quot;money1&quot;: &#123;\n                &quot;type&quot;: &quot;float&quot;\n            &#125;,\n            &quot;money2&quot;: &#123;\n                &quot;type&quot;: &quot;double&quot;\n            &#125;,\n            &quot;sex&quot;: &#123;\n                &quot;type&quot;: &quot;byte&quot;\n            &#125;,\n            &quot;score&quot;: &#123;\n                &quot;type&quot;: &quot;short&quot;\n            &#125;,\n            &quot;is_teenager&quot;: &#123;\n                &quot;type&quot;: &quot;boolean&quot;\n            &#125;,\n            &quot;birthday&quot;: &#123;\n                &quot;type&quot;: &quot;date&quot;\n            &#125;,\n            &quot;relationship&quot;: &#123;\n                &quot;type&quot;: &quot;object&quot;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nnumber_of_shards : 分片数\nnumber_of_replicas : 副本数\nindex：默认true，设置为false的话，那么这个字段就不会被索引(例如密码等敏感信息)\n某个属性一旦被建立，就不能修改了，但是可以新增额外属性\n主要数据类型：\ntext, keyword, string\nlong, integer, short, byte\ndouble, float\nboolean\ndate\nobject\n数组不能混，类型一致\ntext：文字类需要被分词被倒排索引的内容，比如商品名称，商品详情，商品介绍，使用text。\nkeyword：不会被分词，不会被倒排索引，直接匹配搜索，比如订单状态，用户qq，微信号，手机号等，这些精确匹配，无需分词。\n\n四、文档的基本操作4.1 添加文档POST &#x2F;&#123;索引名&#125;&#x2F;_doc&#x2F;&#123;索引ID&#125;（是指索引在es中的id，而不是这条记录的id，比如记录的id从数据库来是1001，并不是这个。如果不写，则自动生成一个字符串。建议和数据id保持一致&gt; ）\n\nPOST &#x2F;index_doc&#x2F;_doc&#x2F;1\n&#123;\n    &quot;id&quot;: 1001,\n    &quot;username&quot;: &quot;username1&quot;,\n    &quot;password&quot;: &quot;password1&quot;,\n    &quot;create_date&quot;: &quot;2021-01-09&quot;\n&#125;\n\n查看索引GET &#x2F;index_doc\n\n返回结果&#123;\n    &quot;index_doc&quot;: &#123;\n        &quot;aliases&quot;: &#123;&#125;,\n        &quot;mappings&quot;: &#123;\n            &quot;properties&quot;: &#123;\n                &quot;create_date&quot;: &#123;\n                    &quot;type&quot;: &quot;date&quot;\n                &#125;,\n                &quot;id&quot;: &#123;\n                    &quot;type&quot;: &quot;long&quot;\n                &#125;,\n                &quot;password&quot;: &#123;\n                    &quot;type&quot;: &quot;text&quot;,\n                    &quot;fields&quot;: &#123;\n                        &quot;keyword&quot;: &#123;\n                            &quot;type&quot;: &quot;keyword&quot;,\n                            &quot;ignore_above&quot;: 256\n                        &#125;\n                    &#125;\n                &#125;,\n                &quot;username&quot;: &#123;\n                    &quot;type&quot;: &quot;text&quot;,\n                    &quot;fields&quot;: &#123;\n                        &quot;keyword&quot;: &#123;\n                            &quot;type&quot;: &quot;keyword&quot;,\n                            &quot;ignore_above&quot;: 256\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;,\n        &quot;settings&quot;: &#123;\n            &quot;index&quot;: &#123;\n                &quot;creation_date&quot;: &quot;1644999567382&quot;,\n                &quot;number_of_shards&quot;: &quot;3&quot;,\n                &quot;number_of_replicas&quot;: &quot;0&quot;,\n                &quot;uuid&quot;: &quot;k3O8-AHVRMuM0KTrJ9q0ww&quot;,\n                &quot;version&quot;: &#123;\n                    &quot;created&quot;: &quot;7040299&quot;\n                &#125;,\n                &quot;provided_name&quot;: &quot;index_doc&quot;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意：\n\n如果索引没有手动建立mappings，那么当插入文档数据的时候，会根据文档类型自动设置属性类型。这个就是es的动态映射，帮我们在index索引库中去建立数据结构的相关配置信息。\n“fields”: {“type”: “keyword”}对一个字段设置多种索引模式，使用text类型做全文检索，也可使用keyword类型做聚合和排序\n“ignore_above” : 256设置字段索引和存储的长度最大值，超过则被忽略\n\n4.2 修改文档4.2.1 局部修改POST &#x2F;index_doc&#x2F;_doc&#x2F;1&#x2F;_update\n&#123;\n    &quot;doc&quot;: &#123;\n        &quot;name&quot;: &quot;update1&quot;\n    &#125;\n&#125;\n\n4.2.2 全局修改PUT &#x2F;index_doc&#x2F;_doc&#x2F;1\n&#123;\n    &quot;id&quot;: 1,\n    &quot;username&quot;: &quot;update2&quot;,\n    &quot;password&quot;: &quot;password1&quot;,\n    &quot;create_date&quot;: &quot;2021-01-09&quot;\n&#125;\n\n同时每次修改后，返回参数中的属性 verison 都会更改\n4.3 删除文档DELETE &#x2F;index_doc&#x2F;_doc&#x2F;1\n\n\n\n\n\n\n\n\n\n\n注：文档删除不是立即删除，文档还是保存在磁盘上，索引增长越来越多，才会把那些曾经标识过删除的，进行清理，从磁盘上移出去。\n4.4 查询文档4.4.1 常规查询GET &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;\nGET &#x2F;index_doc&#x2F;_doc&#x2F;_search\n\n4.4.2 元数据\n_index：文档数据所属那个索引，理解为数据库的某张表即可。\n_type：文档数据属于哪个类型，新版本使用_doc 。\n_id：文档数据的唯一标识，类似数据库中某张表的主键。可以自动生成或者手动指定。\n_score：查询相关度，是否契合用户匹配，分数越高用户的搜索体验越高。\n_version：版本号。\n_source：文档数据，json格式。\n\n4.4.3 定制结果集GET &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;?_source&#x3D;&#123;属性1&#125;,&#123;属性1&#125;...\nGET &#x2F;index_doc&#x2F;_doc&#x2F;_search?_source&#x3D;&#123;属性1&#125;,&#123;属性1&#125;...\n\n4.4.4 判断文档是否存在HEAD &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;\n\n","slug":"Elasticsearch关于 REST API的使用介绍","date":"2022-02-16T06:04:40.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"张春博"},{"id":"490a67515f99d8181b0d3a14207f422b","title":"Kotlin中的伴生对象和静态方法","content":"在日常的开发中，我们经常使用静态变量和静态方法，在java开发中大家经常遇到，那么在kotlin中应该如何使用静态方法和静态对象呢？\njava中的静态方法public class JavaUtils &#123;\n    public static int sum(int a,int b) &#123;\n        return a + b;\n    &#125;\n\n&#125;\n\nKotlin中的静态方法在kotlin中其实是不支持静态方法和静态成员的，但是kotlin支持全局函数和变量。在学习kotlin的过程中，发现了几种方法可以实现kotlin中的静态方法\n\n静态类：使用object关键字，类中的所有的方法都是静态方法。\nobject Utils &#123;\n    fun sum(a:Int,b:Int):Int &#x3D; a+ b\n    const val FLAG &#x3D; true\n&#125;\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    Utils.sum(1,2)\n    Utils.FLAG\n&#125;\n\n在java中的使用方式：\npublic static void main(String[] args) &#123;\n    Utils.INSTANCE.sum(1,2);\n&#125;\n\n如果我们在java中调用也想和在kotlin中调用方式一样，那么应该如何来写？其实很简单，只需要在kotlin中的静态方法或者静态成员上面添加注解 @JvmStatic  和 @JvmField即可\nobject Utils &#123;\n    @JvmStatic\n    fun sum(a:Int,b:Int):Int &#x3D; a+ b\n    @JvmField\n    var FLAG &#x3D; true\n&#125;\n\n那么在java中的调用方式就和kotlin中完全一致了\npublic static void main(String[] args) &#123;\n    Utils.sum(1,2);\n    Utils.FLAG &#x3D; false;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意object关键字的特点：\n只有一个实例的类(单例)\n不能自定义构造方法\n可以实现接口、继承父类\n本质上就是单例模式\n\n通过Kotlin中的伴生对象来实现\n在文章的开始说过，在Kotlin中并没有静态类和成员的概念，但是并不是的kotlin中不能实现类似相应的功能。我们可以通过kotlin中的伴生对象来实现，每个类都可以对应一个伴生对象，伴生对象的成员全局独一份，伴生对象的成员类似java中的静态成员。\nclass ManagerConstants &#123;\n    companion object &#123;\n        val isLogin &#x3D; false\n\n        fun sum(a:Int,b:Int):Int &#123;\n            return a + b\n        &#125;\n\n    &#125;\n&#125;\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    ManagerConstants.sum(1,2)\n    ManagerConstants.isLogin\n&#125;\n\njava中的使用方式：\npublic static void main(String[] args) &#123;\n   ManagerConstants.Companion.sum(1,2);\n  ManagerConstants.Companion.isLogin();\n&#125;\n\n和静态类一样如果想要java和kotlin的使用方式一样，需要在kotlin类中的方法和变量上添加注解    @JvmStatic  和  @JvmField即可\nclass ManagerConstants &#123;\n    companion object &#123;\n        @JvmField\n        val isLogin &#x3D; false\n        @JvmStatic\n        fun sum(a:Int,b:Int):Int &#123;\n            return a + b\n        &#125;\n\n    &#125;\n&#125;\n\n那么在java中的使用方式：\npublic static void main(String[] args) &#123;\n   ManagerConstants.sum(1,2);\n   ManagerConstants.isLogin;\n&#125;\n使用包级函数和变量\nKotlin和Java及C#不同的是，可以在包里面直接声明函数。做法和类中是一样的。\n创建一个名为static.kt的文件，然后在文件中直接写方法和变量\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    var intSum &#x3D; sum(1,2)\n    println(kotlinFlag)\n&#125;\n\n在java中的使用方式：\npublic static void main(String[] args) &#123;\n   StaticKt.sum(1,2);\n&#125;\n\n看到这里相信小伙伴对kotlin中的静态方法的写法已经有了基本的理解，最后需要注意的是，在kotlin中使用静态方法的场景建议使用包级函数、成员的方式来实现。\n","slug":"Kotlin中的伴生对象和静态方法","date":"2022-01-13T12:14:10.000Z","categories_index":"Android","tags_index":"Kotlin","author_index":"张春博"}]