[{"id":"3e4c7b56240531255ad11affc0c50a94","title":"Hadoop搭建简易分布式集群","content":"使用三台机器创建Hadoop简易主从分布式集群，实现一个一主两从的Hadoop集群\n\nHadoop简易分布式集群搭建\n1. 环境准备规划三个虚拟机节点：bd01、bd02、bd03\nbd01 192.168.126.201\n\nbd02 192.168.126.202\n\nbd03 192.168.126.203\n\n\n\n\n\n\n\n\n\n\n注意：每个节点的基础环境都要先配置好，先把ip、hostname、firewalld、ssh免密码登录、JDK这些基础环境配置好。\nSSH免密配置：\n\n首先在bd01上执行ssh-keygen -t rsa,生产SSH密钥\n[root@bd01 ~]# ssh-keygen -t rsa\n[root@bd01 ~]# cd .ssh&#x2F;\n[root@bd01 .ssh]# ll\n-rw-------. 1 root root 1675 5月  31 16:37 id_rsa\n-rw-r--r--. 1 root root  391 5月  31 16:37 id_rsa.pub\n分别执行ssh-copy-id 到bd01、bd02、bd03\n[root@bd01 .ssh]# ssh-copy-id bd01\n[root@bd01 .ssh]# ssh-copy-id bd02\n[root@bd01 .ssh]# ssh-copy-id bd03\n\n2. 配置集群节点之间时间同步集群只要涉及到多个节点的就需要对这些节点做时间同步，如果节点之间时间不同步相差太多，会应该集群的稳定性，甚至导致集群出问题。\n首先在bigdata01节点上操作，使用ntpdate -u ntp.sjtu.edu.cn实现时间同步，但是执行的时候提示找不到ntpdata命令\n[root@bd01 .ssh]# ntpdate -u ntp.sjtu.edu.cn\n-bash: ntpdate: 未找到命令\n\n默认是没有ntpdate命令的，需要使用yum在线安装，bd01、bd02、bd03分别执行命令 yum install -y ntpdate\n[root@bd01 .ssh]# yum install -y ntpdate\n已加载插件：fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * extras: mirrors.aliyun.com\n * updates: mirrors.cn99.com\nbase                                                                            | 3.6 kB  00:00:00     \nextras                                                                          | 2.9 kB  00:00:00     \nupdates                                                                         | 2.9 kB  00:00:00     \n正在解决依赖关系\n--&gt; 正在检查事务\n---&gt; 软件包 ntpdate.x86_64.0.4.2.6p5-29.el7.centos.2 将被 安装\n--&gt; 解决依赖关系完成\n\n依赖关系解决\n\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n Package              架构                版本                                 源                 大小\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n正在安装:\n ntpdate              x86_64              4.2.6p5-29.el7.centos.2              base               87 k\n\n事务概要\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n安装  1 软件包\n\n总下载量：87 k\n安装大小：121 k\nDownloading packages:\nntpdate-4.2.6p5-29.el7.centos.2.x86_64.rpm                                      |  87 kB  00:00:00     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  正在安装    : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                                             1&#x2F;1 \n  验证中      : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                                             1&#x2F;1 \n\n已安装:\n  ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2                                                             \n\n完毕！\n\n然后手动执行ntpdate -u ntp.sjtu.edu.cn 确认是否可以正常执行\n[root@bd01 .ssh]# ntpdate -u ntp.sjtu.edu.cn\n31 May 16:58:43 ntpdate[1665]: adjust time server 202.118.1.81 offset 0.096553 sec\n\n\n\n\n\n\n\n\n\n\n建议把这个同步时间的操作添加到linux的crontab定时器中，每分钟执行一次\n[root@bd01 .ssh]# vim &#x2F;etc&#x2F;crontab \n* * * * * root &#x2F;usr&#x2F;sbin&#x2F;ntpdate -u ntp.sjtu.edu.cn\n\n3. 首先在bd01节点上安装hadoop\n解压hadoop安装包\n[root@bd01 hadoop-3.2.0]# tar -zxvf hadoop-3.2.0.tar.gz -C &#x2F;opt&#x2F;moudle&#x2F;\n[root@bd01 hadoop-3.2.0]# cd &#x2F;opt&#x2F;moudle&#x2F;\n[root@bd01 moudle]# ll\n总用量 0\ndrwxr-xr-x. 9 1001 1002 149 1月   8 2019 hadoop-3.2.0\ndrwxr-xr-x. 7   10  143 245 10月  6 2018 jdk1.8.0_191\n修改hadoop配置文件\n\n首先修改hadoop-env.sh文件，在文件末尾增加环境变量信息\n[root@bd01 hadoop]# vim hadoop-env.sh\nexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;jdk1.8.0_191\nexport HADOOP_LOG_DIR&#x3D;&#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop\n修改core-site.xml文件，注意fs.defaultFS属性中的主机名需要和主节点的主机名保持一致\n[root@bd01 hadoop]# vim core-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;bd01:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;&#x2F;data&#x2F;hadoop_repo&lt;&#x2F;value&gt;\n   &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改hdfs-site.xml文件，把hdfs中文件副本的数量设置为2(默认为3)，最多为2，因为现在集群中有两个从节点，还有secondaryNamenode进程所在的节点信息\n[root@bd01 hadoop]# vim hdfs-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n        &lt;value&gt;2&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;\n        &lt;value&gt;bd01:50090&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改mapred-site.xml，设置mapreduce使用的资源调度框架\n[root@bd01 hadoop]# vim mapred-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;\n        &lt;value&gt;yarn&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改yarn-site.xml，设置yarn上支持运行的服务和环境变量白名单\n\n\n\n\n\n\n\n\n\n注意，针对分布式集群在这个配置文件中还需要设置resourcemanager的hostname，否则nodemanager找不到resourcemanager节点。\n[root@bd01 hadoop]# vim yarn-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;\n        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;\n        &lt;value&gt;bd01&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改workers文件，增加所有从节点的主机名，一个一行\n[root@bd01 hadoop]# vim workers \nbd02\nbd03\n修改启动脚本\n修改start-dfs.sh，stop-dfs.sh这两个脚本文件，在文件前面增加如下内容\n[root@bd01 sbin]# vim start-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n[root@bd01 sbin]# vim stop-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n\n修改start-yarn.sh，stop-yarn.sh这两个脚本文件，在文件前面增加如下内容\n[root@bd01 sbin]# vim start-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n[root@bd01 sbin]# vim stop-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n\n\n\n4. 编写xcall和xsync脚本集群中有多台机器，配置启动集群每次都需要去每台机器上执行一遍相同的命令以及拷贝文件，为了简化操作，编写xcall脚本和xsync脚本\n\n\n\n\n\n\n\n\n\nxcall脚本功能：xcall + 命令，会在集群中的每台机器上都执行一遍此命令，并把结果输出\nxsycn脚本功能：xsync+ 文件/文件夹，会指定的文件/文件夹同步文件到集群中的每台机器中。\n\nxcall脚本\n#!&#x2F;bin&#x2F;bash\npcount&#x3D;$#\nif((pcount&#x3D;&#x3D;0));then\n        echo no args;\n        exit;\nfi\n\n#注释掉下面两行,不注释当前主机会执行两次命令\n#echo -------------localhost----------\n#$@\nfor((host&#x3D;1; host&lt;&#x3D;3; host++)); do\n        echo ----------bd0$host---------\n        ssh bd0$host $@\ndone\n\n功能验证：\n[root@bd01 sbin]# xcall pwd\n----------bd01---------\n&#x2F;root\n----------bd02---------\n&#x2F;root\n----------bd03---------\n&#x2F;root\nxsync脚本\n#!&#x2F;bin&#x2F;bash\n# $#：表示传递给脚本或函数的参数个数。\n#1 获取输入参数个数，如果没有参数，直接退出\npcount&#x3D;$#\nif((pcount&#x3D;&#x3D;0)); then\necho no args;\nexit;\nfi\n\n#2 获取文件名称\np1&#x3D;$1\nfname&#x3D;&#96;basename $p1&#96;\necho fname&#x3D;$fname\n\n#3 获取上级目录到绝对路径\npdir&#x3D;&#96;cd -P $(dirname $p1); pwd&#96;\necho pdir&#x3D;$pdir\n\n#4 获取当前用户名称\nuser&#x3D;&#96;whoami&#96;\n\n#5 循环\nfor((host&#x3D;1; host&lt;4; host++)); do\n       echo --------------- bd0$host ----------------\n       rsync -rvl $pdir&#x2F;$fname $user@bd0$host:$pdir\ndone\n\n功能验证\n[root@bd01 moudle]# mkdir xysnc-test\n[root@bd01 moudle]# xsync xysnc-test&#x2F;\nfname&#x3D;xysnc-test\npdir&#x3D;&#x2F;opt&#x2F;moudle\n--------------- bd01 ----------------\nsending incremental file list\n\nsent 59 bytes  received 17 bytes  50.67 bytes&#x2F;sec\ntotal size is 0  speedup is 0.00\n--------------- bd02 ----------------\nsending incremental file list\nxysnc-test&#x2F;\n\nsent 62 bytes  received 20 bytes  164.00 bytes&#x2F;sec\ntotal size is 0  speedup is 0.00\n--------------- bd03 ----------------\nsending incremental file list\nxysnc-test&#x2F;\n\nsent 62 bytes  received 20 bytes  164.00 bytes&#x2F;sec\ntotal size is 0  speedup is 0.00\n\n5. 把bd01节点上将修改好配置的安装包拷贝到其他两个从节点,并在在bd01节点上格式化HDFS\n同步hadoop到bd02和bd03\n[root@bd01 moudle]# xsync hadoop-3.2.0&#x2F;\n在bd01节点上格式化HDFS\n[root@bd01 hadoop-3.2.0]# bin&#x2F;hdfs namenode -format\n\n如果在后面的日志信息中能看到这一行，则说明namenode格式化成功。\n2022-05-31 21:15:15,324 INFO common.Storage: Storage directory &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name has been successfully formatted.\n\n6. 启动集群在bd01上执行命令\n[root@bd01 hadoop-3.2.0]# sbin&#x2F;start-all.sh \nStarting namenodes on [bd01]\n上一次登录：二 5月 31 21:22:48 CST 2022pts&#x2F;0 上\nStarting datanodes\n上一次登录：二 5月 31 21:23:47 CST 2022pts&#x2F;0 上\nbd03: WARNING: &#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop does not exist. Creating.\nStarting secondary namenodes [bd01]\n上一次登录：二 5月 31 21:23:49 CST 2022pts&#x2F;0 上\nStarting resourcemanager\n上一次登录：二 5月 31 21:23:55 CST 2022pts&#x2F;0 上\nStarting nodemanagers\n上一次登录：二 5月 31 21:24:00 CST 2022pts&#x2F;0 上\n\n7. 验证集群使用xcall命令操作集群，验证hadoop集群是否搭建成功\n[root@bd01 hadoop]# xcall jps\n----------bd01---------\n5520 ResourceManager\n5267 SecondaryNameNode\n5879 Jps\n4973 NameNode\n----------bd02---------\n2402 DataNode\n2516 NodeManager\n2635 Jps\n----------bd03---------\n2022 DataNode\n2137 NodeManager\n2235 Jps\n\n8. 停止集群[root@bd01 hadoop]# stop-all.sh \nStopping namenodes on [bd01]\n上一次登录：二 5月 31 21:24:03 CST 2022pts&#x2F;0 上\nStopping datanodes\n上一次登录：二 5月 31 21:26:35 CST 2022pts&#x2F;0 上\nStopping secondary namenodes [bd01]\n上一次登录：二 5月 31 21:26:36 CST 2022pts&#x2F;0 上\nStopping nodemanagers\n上一次登录：二 5月 31 21:26:39 CST 2022pts&#x2F;0 上\nStopping resourcemanager\n上一次登录：二 5月 31 21:26:42 CST 2022pts&#x2F;0 上\n\nHadoop集群搭建成功！\n","slug":"Hadoop搭建简易分布式集群","date":"2022-05-31T07:14:45.000Z","categories_index":"Hadoop","tags_index":"Hadoop","author_index":"Joker"},{"id":"bb0b195ced0db413665f5bd6467e3504","title":"Hadoop搭建伪分布式集群","content":"\nHadoop伪分布式集群即在一台Linux机器上部署Hadoop集群，通过开通不同的端口来实现相应集群搭建。\n\nHadoop伪分布式集群安装\n这张图代表是一台Linux机器，也可以称为是一个节点，上面安装的有JDK环境\n最上面的是Hadoop集群会启动的进程，其中NameNode、SecondaryNameNode、DataNode是HDFS服务的进程，ResourceManager、NodeManager是YARN服务的进程，MapRedcue在这里没有进程，因为它是一个计算框架，等Hadoop集群安装好了以后MapReduce程序可以在上面执行。\n配置基础环境\n\n\n\n\n\n\n\n\n静态ip配置、hostname配置、firewalld关闭、ssh免密登录、JDK\n安装Hadoop\n首先把下载好的hadoop安装包上传到/opt/software文件夹下\n[root@bigdata-01 software]# ll\n总用量 524788\n-rw-r--r--. 1 root root 345625475 5月  30 14:15 hadoop-3.2.0.tar.gz\n-rwxr-xr-x. 1 root root 191753373 1月  29 2021 jdk-8u191-linux-x64.tar.gz\n解压Hadoop压缩包\ntar -zxvf hadoop-3.2.0.tar.gz -C &#x2F;opt&#x2F;moudle&#x2F;\n[root@bigdata-01 software]# cd &#x2F;opt&#x2F;moudle&#x2F;\n[root@bigdata-01 moudle]# ll\n总用量 0\ndrwxr-xr-x. 9 1001 1002 149 1月   8 2019 hadoop-3.2.0\ndrwxr-xr-x. 7   10  143 245 10月  6 2018 jdk1.8.0_191\n修改Hadoop的配置文件\n\n\n\n\n\n\n\n\n\n主要修改以下文件：\nhadoop-env.sh\ncore-site.xml\nhdfs-site.xml\nmapred-site.xml\nyarn-site.xml workers\n\n首先修改 hadoop-env.sh 文件，增加环境变量信息，添加到hadoop-env.sh 文件末尾即可。\n\n\n\n\n\n\n\n\n\nJAVA_HOME：指定java的安装位置\nHADOOP_LOG_DIR：hadoop的日志的存放目录\n[root@bigdata-01 hadoop]# vim hadoop-env.sh\n# For example, to limit who can execute the namenode command,\n# export HDFS_NAMENODE_USER&#x3D;hdfs\n\nexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;jdk1.8.0_191\nexport HADOOP_LOG_DIR&#x3D;&#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop\n修改core-site.xml 文件\n\n\n\n\n\n\n\n\n\n注意 fs.defaultFS 属性中的主机名需要和你配置的主机名保持一致\n[root@bigdata-01 hadoop]# vim core-site.xml \n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;bigdata-01:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;&#x2F;data&#x2F;hadoop_repo&lt;&#x2F;value&gt;\n   &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改hdfs-site.xml文件，把hdfs中文件副本的数量设置为1，因为现在伪分布集群只有一个节点\n[root@bigdata-01 hadoop]# vim hdfs-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n        &lt;value&gt;1&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改mapred-site.xml，设置mapreduce使用的资源调度框架\n[root@bigdata-01 hadoop]# vim mapred-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;\n        &lt;value&gt;yarn&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改yarn-site.xml，设置yarn上支持运行的服务和环境变量白名单\n[root@bigdata-01 hadoop]# vim yarn-site.xml\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;\n   &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改workers，设置集群中从节点的主机名信息，在这里就一台集群，所以就填写bigdata-01即可\n[root@bigdata-01 hadoop]# vim workers \nbigdata-01\n\n\n格式化HDFS\n[root@bigdata-01 hadoop]# hdfs namenode -format\n\n2022-05-30 15:16:10,058 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n2022-05-30 15:16:10,060 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n2022-05-30 15:16:10,060 INFO util.GSet: VM type       &#x3D; 64-bit\n2022-05-30 15:16:10,060 INFO util.GSet: 0.029999999329447746% max memory 235.9 MB &#x3D; 72.5 KB\n2022-05-30 15:16:10,060 INFO util.GSet: capacity      &#x3D; 2^13 &#x3D; 8192 entries\n2022-05-30 15:16:10,220 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1971366973-192.168.126.200-1653894970205\n2022-05-30 15:16:10,231 INFO common.Storage: Storage directory &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name has been successfully formatted.\n2022-05-30 15:16:10,244 INFO namenode.FSImageFormatProtobuf: Saving image file &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 using no compression\n2022-05-30 15:16:10,381 INFO namenode.FSImageFormatProtobuf: Image file &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\n2022-05-30 15:16:10,391 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;&#x3D; 0\n2022-05-30 15:16:10,398 INFO namenode.NameNode: SHUTDOWN_MSG: \n&#x2F;************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at bigdata-01&#x2F;192.168.126.200\n************************************************************&#x2F;\n\n如果能看到successfully formatted这条信息就说明格式化成功了。\n如果提示错误，一般都是因为配置文件的问题，当然需要根据具体的报错信息去分析问题。\n\n\n\n\n\n\n\n\n\n注意：格式化操作只能执行一次，如果格式化的时候失败了，可以修改配置文件后再执行格式化，如果格式化成功了就不能再重复执行了，否则集群就会出现问题。\n如果确实需要重复执行，那么需要把/data/hadoop_repo目录中的内容全部删除，再执行格式化\n\n启动伪分布集群\n\n使用sbin目录下的start-all.sh脚本\n[root@bigdata-01 hadoop]# start-all.sh \nStarting namenodes on [bigdata-01]\nERROR: Attempting to operate on hdfs namenode as root\nERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\nStarting datanodes\nERROR: Attempting to operate on hdfs datanode as root\nERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.\nStarting secondary namenodes [bigdata-01]\nERROR: Attempting to operate on hdfs secondarynamenode as root\nERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.\nStarting resourcemanager\nERROR: Attempting to operate on yarn resourcemanager as root\nERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.\nStarting nodemanagers\nERROR: Attempting to operate on yarn nodemanager as root\nERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.\n\n解决方案如下：\n修改sbin目录下的start-dfs.sh，stop-dfs.sh这两个脚本文件，在文件前面增加如下内容\n[root@bigdata-01 sbin]# vim start-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n[root@bigdata-01 sbin]# vim stop-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n\n修改sbin目录下的start-yarn.sh，stop-yarn.sh这两个脚本文件，在文件前面增加如下内容\n[root@bigdata-01 sbin]# vim start-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n[root@bigdata-01 sbin]# vim stop-yarn.sh\nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n\n再次启动Hadoop\n[root@bigdata-01 sbin]# start-all.sh \nStarting namenodes on [bigdata-01]\n上一次登录：一 5月 30 14:59:58 CST 2022从 192.168.126.1pts&#x2F;3 上\nStarting datanodes\n上一次登录：一 5月 30 15:30:52 CST 2022pts&#x2F;3 上\nStarting secondary namenodes [bigdata-01]\n上一次登录：一 5月 30 15:30:56 CST 2022pts&#x2F;3 上\nStarting resourcemanager\n上一次登录：一 5月 30 15:31:02 CST 2022pts&#x2F;3 上\nStarting nodemanagers\n上一次登录：一 5月 30 15:31:10 CST 2022pts&#x2F;3 上\n\n\n验证集群进程信息\n执行jps命令可以查看集群的进程信息，去掉Jps这个进程之外还需要有5个进程才说明集群是正常启动的\n[root@bigdata-01 sbin]# jps\n2689 DataNode\n3159 ResourceManager\n3287 NodeManager\n3623 Jps\n2921 SecondaryNameNode\n2557 NameNode\n\n还可以通过webui界面来验证集群服务是否正常\n\nHDFS webui界面：http://192.168.126.200:9870\nYARN webui界面：http://192.168.126.200:8088\n\n\n停止集群\n如果修改了集群的配置文件或者是其它原因要停止集群，可以使用下面命令\n[root@bigdata-01 sbin]# stop-all.sh \nStopping namenodes on [bigdata-01]\n上一次登录：一 5月 30 15:31:12 CST 2022pts&#x2F;3 上\nStopping datanodes\n上一次登录：一 5月 30 15:35:14 CST 2022pts&#x2F;3 上\nStopping secondary namenodes [bigdata-01]\n上一次登录：一 5月 30 15:35:17 CST 2022pts&#x2F;3 上\nStopping nodemanagers\n上一次登录：一 5月 30 15:35:20 CST 2022pts&#x2F;3 上\nStopping resourcemanager\n上一次登录：一 5月 30 15:35:24 CST 2022pts&#x2F;3 上\n\n","slug":"Hadoop搭建伪分布式集群","date":"2022-05-30T06:07:49.000Z","categories_index":"Hadoop","tags_index":"Hadoop","author_index":"Joker"},{"id":"18af339b30adc2c46fa137e5f29a4b24","title":"ES 之分词与内置分词器","content":"分词器是从一串文本中切分一个个的词条，并对每个词条进行标准化。\n\n什么是分词？把文本转换为一个个的单词，分词称之为analysis。es默认只对英文语句做分词，中文不支持，每个中文字都会被拆分为独立的个体。\n\n英文分词：I study in imooc.com\n中文分词：我在慕课网学习\n\nPOST &#x2F;_analyze\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;text&quot;: &quot;text文本&quot;\n&#125;\nPOST &#x2F;my_doc&#x2F;_analyze\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;field&quot;: &quot;name&quot;,\n    &quot;text&quot;: &quot;text文本&quot;\n&#125;\n\nes内置分词器\nstandard：默认分词，单词会被拆分，大小会转换为小写。\nsimple：按照非字母分词。大写转为小写。\nwhitespace：按照空格分词。忽略大小写。\nstop：去除无意义单词，比如the/a/an/is…\nkeyword：不做分词。把整个文本作为一个单独的关键词。\n\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;text&quot;: &quot;My name is Peter Parker,I am a Super Hero. I don&#39;t like the Criminals.&quot;\n&#125;\n\n","slug":"ES 之分词与内置分词器","date":"2022-02-16T12:23:29.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"Joker"},{"id":"e6af55037cba3fe2cceb0e9fb27dac27","title":"Elasticsearch关于 REST API的使用介绍","content":"Elasticsearch提供了大量的REST api来集成、查询和管理数据。下面将在这篇文章中介绍一些经常使用的REST API。\n\n一、集群健康集群健康 | Elasticsearch: 权威指南 | Elastic\nGET &#x2F;_cluster&#x2F;health\n\n和 Elasticsearch 里其他 API 一样，cluster-health 会返回一个 JSON 响应。这对自动化和告警系统来说，非常便于解析。响应中包含了和你集群有关的一些关键信息：\n&#123;\n    &quot;cluster_name&quot;: &quot;joker-elasticsearch&quot;,\n    &quot;status&quot;: &quot;yellow&quot;,\n    &quot;timed_out&quot;: false,\n    &quot;number_of_nodes&quot;: 1,\n    &quot;number_of_data_nodes&quot;: 1,\n    &quot;active_primary_shards&quot;: 8,\n    &quot;active_shards&quot;: 8,\n    &quot;relocating_shards&quot;: 0,\n    &quot;initializing_shards&quot;: 0,\n    &quot;unassigned_shards&quot;: 3,\n    &quot;delayed_unassigned_shards&quot;: 0,\n    &quot;number_of_pending_tasks&quot;: 0,\n    &quot;number_of_in_flight_fetch&quot;: 0,\n    &quot;task_max_waiting_in_queue_millis&quot;: 0,\n    &quot;active_shards_percent_as_number&quot;: 72.72727272727273\n&#125;\n\n响应信息中最重要的一块就是 status 字段。状态可能是下列三个值之一：\ngreen\n所有的主分片和副本分片都已分配。你的集群是 100% 可用的。\nyellow\n所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。\nred\n至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。\ngreen/yellow/red 状态是一个概览你的集群并了解眼下正在发生什么的好办法。剩下来的指标给你列出来集群的状态概要：\n\nnumber_of_nodes 和 number_of_data_nodes 这个命名完全是自描述的。\nactive_primary_shards 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。\nactive_shards 是涵盖了所有索引的_所有_分片的汇总值，即包括副本分片。\nrelocating_shards 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。\ninitializing_shards 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing 状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从 initializing 状态开始。\nunassigned_shards 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片）。\n\n二、索引相关2.1 创建索引PUT &#x2F;index_demo\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;index&quot;: &#123;\n            &quot;number_of_shards&quot;: &quot;2&quot;,\n            &quot;number_of_replicas&quot;: &quot;0&quot;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nnumber_of_shards : 分片数\nnumber_of_replicas : 副本数\n\n2.2 删除索引DELETE &#x2F;index_demo\n\n2.3 查看索引GET &#x2F;_cat&#x2F;indices?v\n\n三、mappings 自定义创建映射3.1 创建索引的同时创建mappingsPUT &#x2F;index_mappings\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;index&quot;: &#123;\n            &quot;number_of_shards&quot;: &quot;3&quot;,\n            &quot;number_of_replicas&quot;: &quot;0&quot;\n        &#125;\n    &#125;,\n    &quot;mappings&quot;: &#123;\n        &quot;properties&quot;: &#123;\n            &quot;realname&quot;: &#123;\n            \t&quot;type&quot;: &quot;text&quot;,\n            \t&quot;index&quot;: true\n            &#125;,\n            &quot;username&quot;: &#123;\n            \t&quot;type&quot;: &quot;keyword&quot;,\n            \t&quot;index&quot;: false\n            &#125;,\n            &quot;id&quot;: &#123;\n        \t    &quot;type&quot;: &quot;long&quot;\n            &#125;,\n            &quot;age&quot;: &#123;\n            \t&quot;type&quot;: &quot;integer&quot;\n            &#125;,\n            &quot;nickname&quot;: &#123;\n                &quot;type&quot;: &quot;keyword&quot;\n            &#125;,\n            &quot;money1&quot;: &#123;\n                &quot;type&quot;: &quot;float&quot;\n            &#125;,\n            &quot;money2&quot;: &#123;\n                &quot;type&quot;: &quot;double&quot;\n            &#125;,\n            &quot;sex&quot;: &#123;\n                &quot;type&quot;: &quot;byte&quot;\n            &#125;,\n            &quot;score&quot;: &#123;\n                &quot;type&quot;: &quot;short&quot;\n            &#125;,\n            &quot;is_teenager&quot;: &#123;\n                &quot;type&quot;: &quot;boolean&quot;\n            &#125;,\n            &quot;birthday&quot;: &#123;\n                &quot;type&quot;: &quot;date&quot;\n            &#125;,\n            &quot;relationship&quot;: &#123;\n                &quot;type&quot;: &quot;object&quot;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nnumber_of_shards : 分片数\nnumber_of_replicas : 副本数\nindex：默认true，设置为false的话，那么这个字段就不会被索引(例如密码等敏感信息)\n某个属性一旦被建立，就不能修改了，但是可以新增额外属性\n主要数据类型：\ntext, keyword, string\nlong, integer, short, byte\ndouble, float\nboolean\ndate\nobject\n数组不能混，类型一致\ntext：文字类需要被分词被倒排索引的内容，比如商品名称，商品详情，商品介绍，使用text。\nkeyword：不会被分词，不会被倒排索引，直接匹配搜索，比如订单状态，用户qq，微信号，手机号等，这些精确匹配，无需分词。\n\n四、文档的基本操作4.1 添加文档POST &#x2F;&#123;索引名&#125;&#x2F;_doc&#x2F;&#123;索引ID&#125;（是指索引在es中的id，而不是这条记录的id，比如记录的id从数据库来是1001，并不是这个。如果不写，则自动生成一个字符串。建议和数据id保持一致&gt; ）\n\nPOST &#x2F;index_doc&#x2F;_doc&#x2F;1\n&#123;\n    &quot;id&quot;: 1001,\n    &quot;username&quot;: &quot;username1&quot;,\n    &quot;password&quot;: &quot;password1&quot;,\n    &quot;create_date&quot;: &quot;2021-01-09&quot;\n&#125;\n\n查看索引GET &#x2F;index_doc\n\n返回结果&#123;\n    &quot;index_doc&quot;: &#123;\n        &quot;aliases&quot;: &#123;&#125;,\n        &quot;mappings&quot;: &#123;\n            &quot;properties&quot;: &#123;\n                &quot;create_date&quot;: &#123;\n                    &quot;type&quot;: &quot;date&quot;\n                &#125;,\n                &quot;id&quot;: &#123;\n                    &quot;type&quot;: &quot;long&quot;\n                &#125;,\n                &quot;password&quot;: &#123;\n                    &quot;type&quot;: &quot;text&quot;,\n                    &quot;fields&quot;: &#123;\n                        &quot;keyword&quot;: &#123;\n                            &quot;type&quot;: &quot;keyword&quot;,\n                            &quot;ignore_above&quot;: 256\n                        &#125;\n                    &#125;\n                &#125;,\n                &quot;username&quot;: &#123;\n                    &quot;type&quot;: &quot;text&quot;,\n                    &quot;fields&quot;: &#123;\n                        &quot;keyword&quot;: &#123;\n                            &quot;type&quot;: &quot;keyword&quot;,\n                            &quot;ignore_above&quot;: 256\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;,\n        &quot;settings&quot;: &#123;\n            &quot;index&quot;: &#123;\n                &quot;creation_date&quot;: &quot;1644999567382&quot;,\n                &quot;number_of_shards&quot;: &quot;3&quot;,\n                &quot;number_of_replicas&quot;: &quot;0&quot;,\n                &quot;uuid&quot;: &quot;k3O8-AHVRMuM0KTrJ9q0ww&quot;,\n                &quot;version&quot;: &#123;\n                    &quot;created&quot;: &quot;7040299&quot;\n                &#125;,\n                &quot;provided_name&quot;: &quot;index_doc&quot;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意：\n\n如果索引没有手动建立mappings，那么当插入文档数据的时候，会根据文档类型自动设置属性类型。这个就是es的动态映射，帮我们在index索引库中去建立数据结构的相关配置信息。\n“fields”: {“type”: “keyword”}对一个字段设置多种索引模式，使用text类型做全文检索，也可使用keyword类型做聚合和排序\n“ignore_above” : 256设置字段索引和存储的长度最大值，超过则被忽略\n\n4.2 修改文档4.2.1 局部修改POST &#x2F;index_doc&#x2F;_doc&#x2F;1&#x2F;_update\n&#123;\n    &quot;doc&quot;: &#123;\n        &quot;name&quot;: &quot;update1&quot;\n    &#125;\n&#125;\n\n4.2.2 全局修改PUT &#x2F;index_doc&#x2F;_doc&#x2F;1\n&#123;\n    &quot;id&quot;: 1,\n    &quot;username&quot;: &quot;update2&quot;,\n    &quot;password&quot;: &quot;password1&quot;,\n    &quot;create_date&quot;: &quot;2021-01-09&quot;\n&#125;\n\n同时每次修改后，返回参数中的属性 verison 都会更改\n4.3 删除文档DELETE &#x2F;index_doc&#x2F;_doc&#x2F;1\n\n\n\n\n\n\n\n\n\n\n注：文档删除不是立即删除，文档还是保存在磁盘上，索引增长越来越多，才会把那些曾经标识过删除的，进行清理，从磁盘上移出去。\n4.4 查询文档4.4.1 常规查询GET &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;\nGET &#x2F;index_doc&#x2F;_doc&#x2F;_search\n\n4.4.2 元数据\n_index：文档数据所属那个索引，理解为数据库的某张表即可。\n_type：文档数据属于哪个类型，新版本使用_doc 。\n_id：文档数据的唯一标识，类似数据库中某张表的主键。可以自动生成或者手动指定。\n_score：查询相关度，是否契合用户匹配，分数越高用户的搜索体验越高。\n_version：版本号。\n_source：文档数据，json格式。\n\n4.4.3 定制结果集GET &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;?_source&#x3D;&#123;属性1&#125;,&#123;属性1&#125;...\nGET &#x2F;index_doc&#x2F;_doc&#x2F;_search?_source&#x3D;&#123;属性1&#125;,&#123;属性1&#125;...\n\n4.4.4 判断文档是否存在HEAD &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;\n\n","slug":"Elasticsearch关于 REST API的使用介绍","date":"2022-02-16T06:04:40.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"Joker"},{"id":"7e9c0ed522e9f463cbadca3b64226a03","title":"Elasticsearch的介绍与安装","content":"Elasticsearch是一个分布式的开源搜索和分析引擎，适用于所有类型的数据，包括文本、数字、地理空间、结构化和非结构化数据。Elasticsearch是在Lucene的基础上开发而成，由Elasticsearch N.V(即现在的Elastic)于2010年首次发布。Elasticsearch以其简单的REST风格的API、分布式特性、速度和可扩展性而闻名，是Elastic Stack的核心组件。\n\n什么是ELK？Elastic Stack通常被称为ELK Stack(代指Elasticsearch、LogStash和Kibana),Elastic Stack是适用于数据采集、充实、存储、分析和可视化的一组开源工具。目前Elastic Stack包括一系列丰富的轻量型数据采集代理，这些代理统称为Beats，可用来向Elasticsearch发送数据。\nLucene vs Solr vs Elasticsearch\n都使用倒排序索引\nLucene是一个类库，基于Java的全文搜索引擎。\nSolr基于Lucene构建的开源引擎，使用Java封装。\nES基于Lucene,高扩展性，支持PB级别的搜索。\n\n\n\n\n\n\n\n\n\n\n正排索引和倒排索引\n正排索引：文档ID作为索引，以文档内容作为记录。但是这样检索关键词的时候很费力，要一个文档一个文档的遍历一遍。\n\n倒排索引：将单词或记录作为索引，将文档ID作为记录，这样便可以方便地通过单词或记录查找到其所在的文档。\n\nElasticsearch安装\n下载Elasticsearch(点击进入Elasticsearch下载页)，选择Linux版本下载。\n\n上传到服务器，进入Elasticsearch的目录下\ntar -zxvf elasticsearch-7.4.2-linux-x86_64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;\n\n\n\n\n\n\n\n\n\n\nElasticsearch的目录结构：\nbin：可执行文件包括elasticsearch启动节点、elasticsearch-plugin安装插件。\nconfig：配置文件\njdk: Elasticsearch依赖的Java环境\nlib：依赖的类库\nlogs：日志文件\nmodules：和ES有关的模块\nplugins: ES的自定义插件\n\n进入Elasticsearch的解压目录内，创建data文件夹\ncd &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;\nmkdir data\n进入config目录进行配置，对elasticsearch.yml进行修改\ncd config&#x2F;\nvim elasticsearch.yml \n配置cluster.name，cluster.name为ES集群名称\ncluster.name: joker-elasticsearch\n配置node.name，node.name为当前ES节点名称\nnode.name: es-node1\n配置path.data和path.logs，path.data为ES数据源路径，path.logs为ES的log日志路径\n# Path to directory where to store the data (separate multiple       locations by comma):\n#\npath.data: &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;data\n#\n# Path to log files:\n#\npath.logs: &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;logs\n配置network.host，network.host为绑定ip地址\n# Set the bind address to a specific IP (IPv4 or IPv6):\nnetwork.host: 0.0.0.0\n配置luster.initial_master_nodes\ncluster.initial_master_nodes: [&quot;es-node1&quot;]\n\n\n\n\n\n\n\n\n\n\n修改jvm.options文件,可以配置ES的运行内存\n\n进入bin目录，启动Elasticsearch\ncd bin&#x2F;\n.&#x2F;elasticsearch -d\n\n\n\n\n\n\n\n\n\n\n在启动Elasticsearch的时候需注意一下几点：\n\n不能以root用户启动Elasticsearch，否则会报错。\n\n启动Elasticsearch报错max virtual memory areas vm.max_map_count    [65530] is too low, increase to at least [262144],\n\n解决方案：修改sysctl.conf文件\n\nvim &#x2F;etc&#x2F;sysctl.conf\n\n\n修改vm.max_map_count的内存大小\n\nvm.max_map_count&#x3D;262145\n\n\n使用sysctl -p命令刷新配置\n\nsysctl -p\n\n以上就是Elasticsearch的基本概念以及安装，不同版本可能有细微差别，如安装出现问题可参考官方文档解决。\n","slug":"Elasticsearch的介绍与安装","date":"2022-01-18T03:05:24.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"Joker"},{"id":"490a67515f99d8181b0d3a14207f422b","title":"Kotlin中的伴生对象和静态方法","content":"在日常的开发中，我们经常使用静态变量和静态方法，在java开发中大家经常遇到，那么在kotlin中应该如何使用静态方法和静态对象呢？\njava中的静态方法public class JavaUtils &#123;\n    public static int sum(int a,int b) &#123;\n        return a + b;\n    &#125;\n\n&#125;\n\nKotlin中的静态方法在kotlin中其实是不支持静态方法和静态成员的，但是kotlin支持全局函数和变量。在学习kotlin的过程中，发现了几种方法可以实现kotlin中的静态方法\n\n静态类：使用object关键字，类中的所有的方法都是静态方法。\nobject Utils &#123;\n    fun sum(a:Int,b:Int):Int &#x3D; a+ b\n    const val FLAG &#x3D; true\n&#125;\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    Utils.sum(1,2)\n    Utils.FLAG\n&#125;\n\n在java中的使用方式：\npublic static void main(String[] args) &#123;\n    Utils.INSTANCE.sum(1,2);\n&#125;\n\n如果我们在java中调用也想和在kotlin中调用方式一样，那么应该如何来写？其实很简单，只需要在kotlin中的静态方法或者静态成员上面添加注解 @JvmStatic  和 @JvmField即可\nobject Utils &#123;\n    @JvmStatic\n    fun sum(a:Int,b:Int):Int &#x3D; a+ b\n    @JvmField\n    var FLAG &#x3D; true\n&#125;\n\n那么在java中的调用方式就和kotlin中完全一致了\npublic static void main(String[] args) &#123;\n    Utils.sum(1,2);\n    Utils.FLAG &#x3D; false;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意object关键字的特点：\n只有一个实例的类(单例)\n不能自定义构造方法\n可以实现接口、继承父类\n本质上就是单例模式\n\n通过Kotlin中的伴生对象来实现\n在文章的开始说过，在Kotlin中并没有静态类和成员的概念，但是并不是的kotlin中不能实现类似相应的功能。我们可以通过kotlin中的伴生对象来实现，每个类都可以对应一个伴生对象，伴生对象的成员全局独一份，伴生对象的成员类似java中的静态成员。\nclass ManagerConstants &#123;\n    companion object &#123;\n        val isLogin &#x3D; false\n\n        fun sum(a:Int,b:Int):Int &#123;\n            return a + b\n        &#125;\n\n    &#125;\n&#125;\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    ManagerConstants.sum(1,2)\n    ManagerConstants.isLogin\n&#125;\n\njava中的使用方式：\npublic static void main(String[] args) &#123;\n   ManagerConstants.Companion.sum(1,2);\n  ManagerConstants.Companion.isLogin();\n&#125;\n\n和静态类一样如果想要java和kotlin的使用方式一样，需要在kotlin类中的方法和变量上添加注解    @JvmStatic  和  @JvmField即可\nclass ManagerConstants &#123;\n    companion object &#123;\n        @JvmField\n        val isLogin &#x3D; false\n        @JvmStatic\n        fun sum(a:Int,b:Int):Int &#123;\n            return a + b\n        &#125;\n\n    &#125;\n&#125;\n\n那么在java中的使用方式：\npublic static void main(String[] args) &#123;\n   ManagerConstants.sum(1,2);\n   ManagerConstants.isLogin;\n&#125;\n使用包级函数和变量\nKotlin和Java及C#不同的是，可以在包里面直接声明函数。做法和类中是一样的。\n创建一个名为static.kt的文件，然后在文件中直接写方法和变量\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    var intSum &#x3D; sum(1,2)\n    println(kotlinFlag)\n&#125;\n\n在java中的使用方式：\npublic static void main(String[] args) &#123;\n   StaticKt.sum(1,2);\n&#125;\n\n看到这里相信小伙伴对kotlin中的静态方法的写法已经有了基本的理解，最后需要注意的是，在kotlin中使用静态方法的场景建议使用包级函数、成员的方式来实现。\n","slug":"Kotlin中的伴生对象和静态方法","date":"2022-01-13T12:14:10.000Z","categories_index":"Android","tags_index":"Kotlin","author_index":"Joker"}]