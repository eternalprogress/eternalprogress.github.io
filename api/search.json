[{"id":"bb0b195ced0db413665f5bd6467e3504","title":"Hadoop搭建伪分布式集群","content":"\nHadoop伪分布式集群即在一台Linux机器上部署Hadoop集群，通过开通不同的端口来实现相应集群搭建。\n\nHadoop伪分布式集群安装\n这张图代表是一台Linux机器，也可以称为是一个节点，上面安装的有JDK环境\n最上面的是Hadoop集群会启动的进程，其中NameNode、SecondaryNameNode、DataNode是HDFS服务的进程，ResourceManager、NodeManager是YARN服务的进程，MapRedcue在这里没有进程，因为它是一个计算框架，等Hadoop集群安装好了以后MapReduce程序可以在上面执行。\n配置基础环境\n\n\n\n\n\n\n\n\n静态ip配置、hostname配置、firewalld关闭、ssh免密登录、JDK\n安装Hadoop\n首先把下载好的hadoop安装包上传到/opt/software文件夹下\n[root@bigdata-01 software]# ll\n总用量 524788\n-rw-r--r--. 1 root root 345625475 5月  30 14:15 hadoop-3.2.0.tar.gz\n-rwxr-xr-x. 1 root root 191753373 1月  29 2021 jdk-8u191-linux-x64.tar.gz\n解压Hadoop压缩包\ntar -zxvf hadoop-3.2.0.tar.gz -C &#x2F;opt&#x2F;moudle&#x2F;\n[root@bigdata-01 software]# cd &#x2F;opt&#x2F;moudle&#x2F;\n[root@bigdata-01 moudle]# ll\n总用量 0\ndrwxr-xr-x. 9 1001 1002 149 1月   8 2019 hadoop-3.2.0\ndrwxr-xr-x. 7   10  143 245 10月  6 2018 jdk1.8.0_191\n修改Hadoop的配置文件\n\n\n\n\n\n\n\n\n\n主要修改以下文件：\nhadoop-env.sh\ncore-site.xml\nhdfs-site.xml\nmapred-site.xml\nyarn-site.xml workers\n\n首先修改 hadoop-env.sh 文件，增加环境变量信息，添加到hadoop-env.sh 文件末尾即可。\n\n\n\n\n\n\n\n\n\nJAVA_HOME：指定java的安装位置\nHADOOP_LOG_DIR：hadoop的日志的存放目录\n[root@bigdata-01 hadoop]# vim hadoop-env.sh\n# For example, to limit who can execute the namenode command,\n# export HDFS_NAMENODE_USER&#x3D;hdfs\n\nexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;moudle&#x2F;jdk1.8.0_191\nexport HADOOP_LOG_DIR&#x3D;&#x2F;data&#x2F;hadoop_repo&#x2F;logs&#x2F;hadoop\n修改core-site.xml 文件\n\n\n\n\n\n\n\n\n\n注意 fs.defaultFS 属性中的主机名需要和你配置的主机名保持一致\n[root@bigdata-01 hadoop]# vim core-site.xml \n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;bigdata-01:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;&#x2F;data&#x2F;hadoop_repo&lt;&#x2F;value&gt;\n   &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改hdfs-site.xml文件，把hdfs中文件副本的数量设置为1，因为现在伪分布集群只有一个节点\n[root@bigdata-01 hadoop]# vim hdfs-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n        &lt;value&gt;1&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改mapred-site.xml，设置mapreduce使用的资源调度框架\n[root@bigdata-01 hadoop]# vim mapred-site.xml \n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;\n        &lt;value&gt;yarn&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改yarn-site.xml，设置yarn上支持运行的服务和环境变量白名单\n[root@bigdata-01 hadoop]# vim yarn-site.xml\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;\n   &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n修改workers，设置集群中从节点的主机名信息，在这里就一台集群，所以就填写bigdata-01即可\n[root@bigdata-01 hadoop]# vim workers \nbigdata-01\n\n\n格式化HDFS\n[root@bigdata-01 hadoop]# hdfs namenode -format\n\n2022-05-30 15:16:10,058 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n2022-05-30 15:16:10,060 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n2022-05-30 15:16:10,060 INFO util.GSet: VM type       &#x3D; 64-bit\n2022-05-30 15:16:10,060 INFO util.GSet: 0.029999999329447746% max memory 235.9 MB &#x3D; 72.5 KB\n2022-05-30 15:16:10,060 INFO util.GSet: capacity      &#x3D; 2^13 &#x3D; 8192 entries\n2022-05-30 15:16:10,220 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1971366973-192.168.126.200-1653894970205\n2022-05-30 15:16:10,231 INFO common.Storage: Storage directory &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name has been successfully formatted.\n2022-05-30 15:16:10,244 INFO namenode.FSImageFormatProtobuf: Saving image file &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 using no compression\n2022-05-30 15:16:10,381 INFO namenode.FSImageFormatProtobuf: Image file &#x2F;data&#x2F;hadoop_repo&#x2F;dfs&#x2F;name&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\n2022-05-30 15:16:10,391 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;&#x3D; 0\n2022-05-30 15:16:10,398 INFO namenode.NameNode: SHUTDOWN_MSG: \n&#x2F;************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at bigdata-01&#x2F;192.168.126.200\n************************************************************&#x2F;\n\n如果能看到successfully formatted这条信息就说明格式化成功了。\n如果提示错误，一般都是因为配置文件的问题，当然需要根据具体的报错信息去分析问题。\n\n\n\n\n\n\n\n\n\n注意：格式化操作只能执行一次，如果格式化的时候失败了，可以修改配置文件后再执行格式化，如果格式化成功了就不能再重复执行了，否则集群就会出现问题。\n如果确实需要重复执行，那么需要把/data/hadoop_repo目录中的内容全部删除，再执行格式化\n\n启动伪分布集群\n\n使用sbin目录下的start-all.sh脚本\n[root@bigdata-01 hadoop]# start-all.sh \nStarting namenodes on [bigdata-01]\nERROR: Attempting to operate on hdfs namenode as root\nERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\nStarting datanodes\nERROR: Attempting to operate on hdfs datanode as root\nERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.\nStarting secondary namenodes [bigdata-01]\nERROR: Attempting to operate on hdfs secondarynamenode as root\nERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.\nStarting resourcemanager\nERROR: Attempting to operate on yarn resourcemanager as root\nERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.\nStarting nodemanagers\nERROR: Attempting to operate on yarn nodemanager as root\nERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.\n\n解决方案如下：\n修改sbin目录下的start-dfs.sh，stop-dfs.sh这两个脚本文件，在文件前面增加如下内容\n[root@bigdata-01 sbin]# vim start-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n[root@bigdata-01 sbin]# vim stop-dfs.sh \nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n\n修改sbin目录下的start-yarn.sh，stop-yarn.sh这两个脚本文件，在文件前面增加如下内容\n[root@bigdata-01 sbin]# vim start-yarn.sh \nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n[root@bigdata-01 sbin]# vim stop-yarn.sh\nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n\n再次启动Hadoop\n[root@bigdata-01 sbin]# start-all.sh \nStarting namenodes on [bigdata-01]\n上一次登录：一 5月 30 14:59:58 CST 2022从 192.168.126.1pts&#x2F;3 上\nStarting datanodes\n上一次登录：一 5月 30 15:30:52 CST 2022pts&#x2F;3 上\nStarting secondary namenodes [bigdata-01]\n上一次登录：一 5月 30 15:30:56 CST 2022pts&#x2F;3 上\nStarting resourcemanager\n上一次登录：一 5月 30 15:31:02 CST 2022pts&#x2F;3 上\nStarting nodemanagers\n上一次登录：一 5月 30 15:31:10 CST 2022pts&#x2F;3 上\n\n\n验证集群进程信息\n执行jps命令可以查看集群的进程信息，去掉Jps这个进程之外还需要有5个进程才说明集群是正常启动的\n[root@bigdata-01 sbin]# jps\n2689 DataNode\n3159 ResourceManager\n3287 NodeManager\n3623 Jps\n2921 SecondaryNameNode\n2557 NameNode\n\n还可以通过webui界面来验证集群服务是否正常\n\nHDFS webui界面：http://192.168.126.200:9870\nYARN webui界面：http://192.168.126.200:8088\n\n\n停止集群\n如果修改了集群的配置文件或者是其它原因要停止集群，可以使用下面命令\n[root@bigdata-01 sbin]# stop-all.sh \nStopping namenodes on [bigdata-01]\n上一次登录：一 5月 30 15:31:12 CST 2022pts&#x2F;3 上\nStopping datanodes\n上一次登录：一 5月 30 15:35:14 CST 2022pts&#x2F;3 上\nStopping secondary namenodes [bigdata-01]\n上一次登录：一 5月 30 15:35:17 CST 2022pts&#x2F;3 上\nStopping nodemanagers\n上一次登录：一 5月 30 15:35:20 CST 2022pts&#x2F;3 上\nStopping resourcemanager\n上一次登录：一 5月 30 15:35:24 CST 2022pts&#x2F;3 上\n\n","slug":"Hadoop搭建伪分布式集群","date":"2022-05-30T06:07:49.000Z","categories_index":"Hadoop","tags_index":"Hadoop","author_index":"Joker"},{"id":"18af339b30adc2c46fa137e5f29a4b24","title":"ES 之分词与内置分词器","content":"分词器是从一串文本中切分一个个的词条，并对每个词条进行标准化。\n\n什么是分词？把文本转换为一个个的单词，分词称之为analysis。es默认只对英文语句做分词，中文不支持，每个中文字都会被拆分为独立的个体。\n\n英文分词：I study in imooc.com\n中文分词：我在慕课网学习\n\nPOST &#x2F;_analyze\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;text&quot;: &quot;text文本&quot;\n&#125;\nPOST &#x2F;my_doc&#x2F;_analyze\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;field&quot;: &quot;name&quot;,\n    &quot;text&quot;: &quot;text文本&quot;\n&#125;\n\nes内置分词器\nstandard：默认分词，单词会被拆分，大小会转换为小写。\nsimple：按照非字母分词。大写转为小写。\nwhitespace：按照空格分词。忽略大小写。\nstop：去除无意义单词，比如the/a/an/is…\nkeyword：不做分词。把整个文本作为一个单独的关键词。\n\n&#123;\n    &quot;analyzer&quot;: &quot;standard&quot;,\n    &quot;text&quot;: &quot;My name is Peter Parker,I am a Super Hero. I don&#39;t like the Criminals.&quot;\n&#125;\n\n","slug":"ES 之分词与内置分词器","date":"2022-02-16T12:23:29.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"Joker"},{"id":"e6af55037cba3fe2cceb0e9fb27dac27","title":"Elasticsearch关于 REST API的使用介绍","content":"Elasticsearch提供了大量的REST api来集成、查询和管理数据。下面将在这篇文章中介绍一些经常使用的REST API。\n\n一、集群健康集群健康 | Elasticsearch: 权威指南 | Elastic\nGET &#x2F;_cluster&#x2F;health\n\n和 Elasticsearch 里其他 API 一样，cluster-health 会返回一个 JSON 响应。这对自动化和告警系统来说，非常便于解析。响应中包含了和你集群有关的一些关键信息：\n&#123;\n    &quot;cluster_name&quot;: &quot;joker-elasticsearch&quot;,\n    &quot;status&quot;: &quot;yellow&quot;,\n    &quot;timed_out&quot;: false,\n    &quot;number_of_nodes&quot;: 1,\n    &quot;number_of_data_nodes&quot;: 1,\n    &quot;active_primary_shards&quot;: 8,\n    &quot;active_shards&quot;: 8,\n    &quot;relocating_shards&quot;: 0,\n    &quot;initializing_shards&quot;: 0,\n    &quot;unassigned_shards&quot;: 3,\n    &quot;delayed_unassigned_shards&quot;: 0,\n    &quot;number_of_pending_tasks&quot;: 0,\n    &quot;number_of_in_flight_fetch&quot;: 0,\n    &quot;task_max_waiting_in_queue_millis&quot;: 0,\n    &quot;active_shards_percent_as_number&quot;: 72.72727272727273\n&#125;\n\n响应信息中最重要的一块就是 status 字段。状态可能是下列三个值之一：\ngreen\n所有的主分片和副本分片都已分配。你的集群是 100% 可用的。\nyellow\n所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。\nred\n至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。\ngreen/yellow/red 状态是一个概览你的集群并了解眼下正在发生什么的好办法。剩下来的指标给你列出来集群的状态概要：\n\nnumber_of_nodes 和 number_of_data_nodes 这个命名完全是自描述的。\nactive_primary_shards 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。\nactive_shards 是涵盖了所有索引的_所有_分片的汇总值，即包括副本分片。\nrelocating_shards 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。\ninitializing_shards 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing 状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从 initializing 状态开始。\nunassigned_shards 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片）。\n\n二、索引相关2.1 创建索引PUT &#x2F;index_demo\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;index&quot;: &#123;\n            &quot;number_of_shards&quot;: &quot;2&quot;,\n            &quot;number_of_replicas&quot;: &quot;0&quot;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nnumber_of_shards : 分片数\nnumber_of_replicas : 副本数\n\n2.2 删除索引DELETE &#x2F;index_demo\n\n2.3 查看索引GET &#x2F;_cat&#x2F;indices?v\n\n三、mappings 自定义创建映射3.1 创建索引的同时创建mappingsPUT &#x2F;index_mappings\n&#123;\n    &quot;settings&quot;: &#123;\n        &quot;index&quot;: &#123;\n            &quot;number_of_shards&quot;: &quot;3&quot;,\n            &quot;number_of_replicas&quot;: &quot;0&quot;\n        &#125;\n    &#125;,\n    &quot;mappings&quot;: &#123;\n        &quot;properties&quot;: &#123;\n            &quot;realname&quot;: &#123;\n            \t&quot;type&quot;: &quot;text&quot;,\n            \t&quot;index&quot;: true\n            &#125;,\n            &quot;username&quot;: &#123;\n            \t&quot;type&quot;: &quot;keyword&quot;,\n            \t&quot;index&quot;: false\n            &#125;,\n            &quot;id&quot;: &#123;\n        \t    &quot;type&quot;: &quot;long&quot;\n            &#125;,\n            &quot;age&quot;: &#123;\n            \t&quot;type&quot;: &quot;integer&quot;\n            &#125;,\n            &quot;nickname&quot;: &#123;\n                &quot;type&quot;: &quot;keyword&quot;\n            &#125;,\n            &quot;money1&quot;: &#123;\n                &quot;type&quot;: &quot;float&quot;\n            &#125;,\n            &quot;money2&quot;: &#123;\n                &quot;type&quot;: &quot;double&quot;\n            &#125;,\n            &quot;sex&quot;: &#123;\n                &quot;type&quot;: &quot;byte&quot;\n            &#125;,\n            &quot;score&quot;: &#123;\n                &quot;type&quot;: &quot;short&quot;\n            &#125;,\n            &quot;is_teenager&quot;: &#123;\n                &quot;type&quot;: &quot;boolean&quot;\n            &#125;,\n            &quot;birthday&quot;: &#123;\n                &quot;type&quot;: &quot;date&quot;\n            &#125;,\n            &quot;relationship&quot;: &#123;\n                &quot;type&quot;: &quot;object&quot;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nnumber_of_shards : 分片数\nnumber_of_replicas : 副本数\nindex：默认true，设置为false的话，那么这个字段就不会被索引(例如密码等敏感信息)\n某个属性一旦被建立，就不能修改了，但是可以新增额外属性\n主要数据类型：\ntext, keyword, string\nlong, integer, short, byte\ndouble, float\nboolean\ndate\nobject\n数组不能混，类型一致\ntext：文字类需要被分词被倒排索引的内容，比如商品名称，商品详情，商品介绍，使用text。\nkeyword：不会被分词，不会被倒排索引，直接匹配搜索，比如订单状态，用户qq，微信号，手机号等，这些精确匹配，无需分词。\n\n四、文档的基本操作4.1 添加文档POST &#x2F;&#123;索引名&#125;&#x2F;_doc&#x2F;&#123;索引ID&#125;（是指索引在es中的id，而不是这条记录的id，比如记录的id从数据库来是1001，并不是这个。如果不写，则自动生成一个字符串。建议和数据id保持一致&gt; ）\n\nPOST &#x2F;index_doc&#x2F;_doc&#x2F;1\n&#123;\n    &quot;id&quot;: 1001,\n    &quot;username&quot;: &quot;username1&quot;,\n    &quot;password&quot;: &quot;password1&quot;,\n    &quot;create_date&quot;: &quot;2021-01-09&quot;\n&#125;\n\n查看索引GET &#x2F;index_doc\n\n返回结果&#123;\n    &quot;index_doc&quot;: &#123;\n        &quot;aliases&quot;: &#123;&#125;,\n        &quot;mappings&quot;: &#123;\n            &quot;properties&quot;: &#123;\n                &quot;create_date&quot;: &#123;\n                    &quot;type&quot;: &quot;date&quot;\n                &#125;,\n                &quot;id&quot;: &#123;\n                    &quot;type&quot;: &quot;long&quot;\n                &#125;,\n                &quot;password&quot;: &#123;\n                    &quot;type&quot;: &quot;text&quot;,\n                    &quot;fields&quot;: &#123;\n                        &quot;keyword&quot;: &#123;\n                            &quot;type&quot;: &quot;keyword&quot;,\n                            &quot;ignore_above&quot;: 256\n                        &#125;\n                    &#125;\n                &#125;,\n                &quot;username&quot;: &#123;\n                    &quot;type&quot;: &quot;text&quot;,\n                    &quot;fields&quot;: &#123;\n                        &quot;keyword&quot;: &#123;\n                            &quot;type&quot;: &quot;keyword&quot;,\n                            &quot;ignore_above&quot;: 256\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;,\n        &quot;settings&quot;: &#123;\n            &quot;index&quot;: &#123;\n                &quot;creation_date&quot;: &quot;1644999567382&quot;,\n                &quot;number_of_shards&quot;: &quot;3&quot;,\n                &quot;number_of_replicas&quot;: &quot;0&quot;,\n                &quot;uuid&quot;: &quot;k3O8-AHVRMuM0KTrJ9q0ww&quot;,\n                &quot;version&quot;: &#123;\n                    &quot;created&quot;: &quot;7040299&quot;\n                &#125;,\n                &quot;provided_name&quot;: &quot;index_doc&quot;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意：\n\n如果索引没有手动建立mappings，那么当插入文档数据的时候，会根据文档类型自动设置属性类型。这个就是es的动态映射，帮我们在index索引库中去建立数据结构的相关配置信息。\n“fields”: {“type”: “keyword”}对一个字段设置多种索引模式，使用text类型做全文检索，也可使用keyword类型做聚合和排序\n“ignore_above” : 256设置字段索引和存储的长度最大值，超过则被忽略\n\n4.2 修改文档4.2.1 局部修改POST &#x2F;index_doc&#x2F;_doc&#x2F;1&#x2F;_update\n&#123;\n    &quot;doc&quot;: &#123;\n        &quot;name&quot;: &quot;update1&quot;\n    &#125;\n&#125;\n\n4.2.2 全局修改PUT &#x2F;index_doc&#x2F;_doc&#x2F;1\n&#123;\n    &quot;id&quot;: 1,\n    &quot;username&quot;: &quot;update2&quot;,\n    &quot;password&quot;: &quot;password1&quot;,\n    &quot;create_date&quot;: &quot;2021-01-09&quot;\n&#125;\n\n同时每次修改后，返回参数中的属性 verison 都会更改\n4.3 删除文档DELETE &#x2F;index_doc&#x2F;_doc&#x2F;1\n\n\n\n\n\n\n\n\n\n\n注：文档删除不是立即删除，文档还是保存在磁盘上，索引增长越来越多，才会把那些曾经标识过删除的，进行清理，从磁盘上移出去。\n4.4 查询文档4.4.1 常规查询GET &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;\nGET &#x2F;index_doc&#x2F;_doc&#x2F;_search\n\n4.4.2 元数据\n_index：文档数据所属那个索引，理解为数据库的某张表即可。\n_type：文档数据属于哪个类型，新版本使用_doc 。\n_id：文档数据的唯一标识，类似数据库中某张表的主键。可以自动生成或者手动指定。\n_score：查询相关度，是否契合用户匹配，分数越高用户的搜索体验越高。\n_version：版本号。\n_source：文档数据，json格式。\n\n4.4.3 定制结果集GET &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;?_source&#x3D;&#123;属性1&#125;,&#123;属性1&#125;...\nGET &#x2F;index_doc&#x2F;_doc&#x2F;_search?_source&#x3D;&#123;属性1&#125;,&#123;属性1&#125;...\n\n4.4.4 判断文档是否存在HEAD &#x2F;index_doc&#x2F;_doc&#x2F;&#123;索引ID&#125;\n\n","slug":"Elasticsearch关于 REST API的使用介绍","date":"2022-02-16T06:04:40.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"Joker"},{"id":"7e9c0ed522e9f463cbadca3b64226a03","title":"Elasticsearch的介绍与安装","content":"Elasticsearch是一个分布式的开源搜索和分析引擎，适用于所有类型的数据，包括文本、数字、地理空间、结构化和非结构化数据。Elasticsearch是在Lucene的基础上开发而成，由Elasticsearch N.V(即现在的Elastic)于2010年首次发布。Elasticsearch以其简单的REST风格的API、分布式特性、速度和可扩展性而闻名，是Elastic Stack的核心组件。\n\n什么是ELK？Elastic Stack通常被称为ELK Stack(代指Elasticsearch、LogStash和Kibana),Elastic Stack是适用于数据采集、充实、存储、分析和可视化的一组开源工具。目前Elastic Stack包括一系列丰富的轻量型数据采集代理，这些代理统称为Beats，可用来向Elasticsearch发送数据。\nLucene vs Solr vs Elasticsearch\n都使用倒排序索引\nLucene是一个类库，基于Java的全文搜索引擎。\nSolr基于Lucene构建的开源引擎，使用Java封装。\nES基于Lucene,高扩展性，支持PB级别的搜索。\n\n\n\n\n\n\n\n\n\n\n正排索引和倒排索引\n正排索引：文档ID作为索引，以文档内容作为记录。但是这样检索关键词的时候很费力，要一个文档一个文档的遍历一遍。\n\n倒排索引：将单词或记录作为索引，将文档ID作为记录，这样便可以方便地通过单词或记录查找到其所在的文档。\n\nElasticsearch安装\n下载Elasticsearch(点击进入Elasticsearch下载页)，选择Linux版本下载。\n\n上传到服务器，进入Elasticsearch的目录下\ntar -zxvf elasticsearch-7.4.2-linux-x86_64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;\n\n\n\n\n\n\n\n\n\n\nElasticsearch的目录结构：\nbin：可执行文件包括elasticsearch启动节点、elasticsearch-plugin安装插件。\nconfig：配置文件\njdk: Elasticsearch依赖的Java环境\nlib：依赖的类库\nlogs：日志文件\nmodules：和ES有关的模块\nplugins: ES的自定义插件\n\n进入Elasticsearch的解压目录内，创建data文件夹\ncd &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;\nmkdir data\n进入config目录进行配置，对elasticsearch.yml进行修改\ncd config&#x2F;\nvim elasticsearch.yml \n配置cluster.name，cluster.name为ES集群名称\ncluster.name: joker-elasticsearch\n配置node.name，node.name为当前ES节点名称\nnode.name: es-node1\n配置path.data和path.logs，path.data为ES数据源路径，path.logs为ES的log日志路径\n# Path to directory where to store the data (separate multiple       locations by comma):\n#\npath.data: &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;data\n#\n# Path to log files:\n#\npath.logs: &#x2F;usr&#x2F;local&#x2F;elasticsearch-7.4.2&#x2F;logs\n配置network.host，network.host为绑定ip地址\n# Set the bind address to a specific IP (IPv4 or IPv6):\nnetwork.host: 0.0.0.0\n配置luster.initial_master_nodes\ncluster.initial_master_nodes: [&quot;es-node1&quot;]\n\n\n\n\n\n\n\n\n\n\n修改jvm.options文件,可以配置ES的运行内存\n\n进入bin目录，启动Elasticsearch\ncd bin&#x2F;\n.&#x2F;elasticsearch -d\n\n\n\n\n\n\n\n\n\n\n在启动Elasticsearch的时候需注意一下几点：\n\n不能以root用户启动Elasticsearch，否则会报错。\n\n启动Elasticsearch报错max virtual memory areas vm.max_map_count    [65530] is too low, increase to at least [262144],\n\n解决方案：修改sysctl.conf文件\n\nvim &#x2F;etc&#x2F;sysctl.conf\n\n\n修改vm.max_map_count的内存大小\n\nvm.max_map_count&#x3D;262145\n\n\n使用sysctl -p命令刷新配置\n\nsysctl -p\n\n以上就是Elasticsearch的基本概念以及安装，不同版本可能有细微差别，如安装出现问题可参考官方文档解决。\n","slug":"Elasticsearch的介绍与安装","date":"2022-01-18T03:05:24.000Z","categories_index":"ELK","tags_index":"Elasticsearch","author_index":"Joker"},{"id":"490a67515f99d8181b0d3a14207f422b","title":"Kotlin中的伴生对象和静态方法","content":"在日常的开发中，我们经常使用静态变量和静态方法，在java开发中大家经常遇到，那么在kotlin中应该如何使用静态方法和静态对象呢？\njava中的静态方法public class JavaUtils &#123;\n    public static int sum(int a,int b) &#123;\n        return a + b;\n    &#125;\n\n&#125;\n\nKotlin中的静态方法在kotlin中其实是不支持静态方法和静态成员的，但是kotlin支持全局函数和变量。在学习kotlin的过程中，发现了几种方法可以实现kotlin中的静态方法\n\n静态类：使用object关键字，类中的所有的方法都是静态方法。\nobject Utils &#123;\n    fun sum(a:Int,b:Int):Int &#x3D; a+ b\n    const val FLAG &#x3D; true\n&#125;\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    Utils.sum(1,2)\n    Utils.FLAG\n&#125;\n\n在java中的使用方式：\npublic static void main(String[] args) &#123;\n    Utils.INSTANCE.sum(1,2);\n&#125;\n\n如果我们在java中调用也想和在kotlin中调用方式一样，那么应该如何来写？其实很简单，只需要在kotlin中的静态方法或者静态成员上面添加注解 @JvmStatic  和 @JvmField即可\nobject Utils &#123;\n    @JvmStatic\n    fun sum(a:Int,b:Int):Int &#x3D; a+ b\n    @JvmField\n    var FLAG &#x3D; true\n&#125;\n\n那么在java中的调用方式就和kotlin中完全一致了\npublic static void main(String[] args) &#123;\n    Utils.sum(1,2);\n    Utils.FLAG &#x3D; false;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意object关键字的特点：\n只有一个实例的类(单例)\n不能自定义构造方法\n可以实现接口、继承父类\n本质上就是单例模式\n\n通过Kotlin中的伴生对象来实现\n在文章的开始说过，在Kotlin中并没有静态类和成员的概念，但是并不是的kotlin中不能实现类似相应的功能。我们可以通过kotlin中的伴生对象来实现，每个类都可以对应一个伴生对象，伴生对象的成员全局独一份，伴生对象的成员类似java中的静态成员。\nclass ManagerConstants &#123;\n    companion object &#123;\n        val isLogin &#x3D; false\n\n        fun sum(a:Int,b:Int):Int &#123;\n            return a + b\n        &#125;\n\n    &#125;\n&#125;\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    ManagerConstants.sum(1,2)\n    ManagerConstants.isLogin\n&#125;\n\njava中的使用方式：\npublic static void main(String[] args) &#123;\n   ManagerConstants.Companion.sum(1,2);\n  ManagerConstants.Companion.isLogin();\n&#125;\n\n和静态类一样如果想要java和kotlin的使用方式一样，需要在kotlin类中的方法和变量上添加注解    @JvmStatic  和  @JvmField即可\nclass ManagerConstants &#123;\n    companion object &#123;\n        @JvmField\n        val isLogin &#x3D; false\n        @JvmStatic\n        fun sum(a:Int,b:Int):Int &#123;\n            return a + b\n        &#125;\n\n    &#125;\n&#125;\n\n那么在java中的使用方式：\npublic static void main(String[] args) &#123;\n   ManagerConstants.sum(1,2);\n   ManagerConstants.isLogin;\n&#125;\n使用包级函数和变量\nKotlin和Java及C#不同的是，可以在包里面直接声明函数。做法和类中是一样的。\n创建一个名为static.kt的文件，然后在文件中直接写方法和变量\n\n使用方式：\nfun main(args: Array&lt;String&gt;) &#123;\n    var intSum &#x3D; sum(1,2)\n    println(kotlinFlag)\n&#125;\n\n在java中的使用方式：\npublic static void main(String[] args) &#123;\n   StaticKt.sum(1,2);\n&#125;\n\n看到这里相信小伙伴对kotlin中的静态方法的写法已经有了基本的理解，最后需要注意的是，在kotlin中使用静态方法的场景建议使用包级函数、成员的方式来实现。\n","slug":"Kotlin中的伴生对象和静态方法","date":"2022-01-13T12:14:10.000Z","categories_index":"Android","tags_index":"Kotlin","author_index":"Joker"}]